{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#temporal-graph-analysis-with-tgx-wsdm-2024-demo-track","title":"Temporal Graph Analysis with TGX (WSDM 2024 Demo Track)","text":"<p>TGX supports all datasets from TGB and Poursafaei et al. 2022 as well as any custom dataset in <code>.csv</code> format.  TGX provides numerous temporal graph visualization plots and statistics out of the box.</p>"},{"location":"#data-loading","title":"Data Loading","text":"<p>For detailed tutorial on how to load the datasets into <code>tgx.Graph</code>, see <code>docs/tutorials/data_loader.ipynb</code></p> <ol> <li>Load TGB datasets</li> </ol> <pre><code>import tgx\ndataset = tgx.tgb_data(\"tgbl-wiki\")\nctdg = tgx.Graph(dataset)\n</code></pre> <ol> <li>Load built-in datasets</li> </ol> <pre><code>dataset = tgx.builtin.uci()\nctdg = tgx.Graph(dataset)\n</code></pre> <ol> <li>Load custom datasets from <code>.csv</code> </li> </ol> <pre><code>from tgx.io.read import read_csv\ntoy_fname = \"docs/tutorials/toy_data.csv\"\nedgelist = read_csv(toy_fname, header=True,index=False, t_col=0,)\ntgx.Graph(edgelist=edgelist)\n</code></pre>"},{"location":"#visualization-and-statistics","title":"Visualization and Statistics","text":"<p>For detailed tutorial on how to generate visualizations and compute statistics for temporal graphs, see <code>docs/tutorials/data_viz_stats.ipynb</code></p> <ol> <li>Discretize the network (required for viz)</li> </ol> <pre><code>dataset = tgx.builtin.uci()\nctdg = tgx.Graph(dataset)\ntime_scale = \"weekly\"\ndtdg, ts_list = ctdg.discretize(time_scale=time_scale, store_unix=True)\n</code></pre> <ol> <li>Plot the number of nodes over time</li> </ol> <pre><code>tgx.degree_over_time(dtdg, network_name=\"uci\")\n</code></pre> <ol> <li>Compute novelty index</li> </ol> <pre><code>tgx.get_novelty(dtdg)\n</code></pre>"},{"location":"#install-dependency","title":"Install dependency","text":"<p>Our implementation works with python &gt;= 3.9 and can be installed as follows</p> <ol> <li>set up virtual environment (conda should work as well)</li> </ol> <pre><code>python -m venv ~/tgx_env/\nsource ~/tgx_env/bin/activate\n</code></pre> <ol> <li>install external packages</li> </ol> <pre><code>pip install -r requirements.txt\n</code></pre> <ol> <li>install local dependencies under root directory <code>/TGX</code></li> </ol> <pre><code>pip install -e .\n</code></pre> <ol> <li>[alternatively] install from test-pypi</li> </ol> <pre><code>pip install -i https://test.pypi.org/simple/ py-tgx\n</code></pre> <p>You can specify the version with <code>==</code>, note that the pypi version might not always be the most updated version</p> <ol> <li>[optional] install mkdocs dependencies to serve the documentation locally</li> </ol> <pre><code>pip install mkdocs-glightbox\n</code></pre>"},{"location":"#creating-new-branch","title":"Creating new branch","text":"<p>first create the branch on github</p> <pre><code>git fetch origin\n\ngit checkout -b test origin/test\n</code></pre>"},{"location":"contribute/","title":"Contribute","text":""},{"location":"contribute/#tgx-community-contribution-guidelines","title":"TGX Community Contribution Guidelines","text":"<p>TGX is a community driven project and we hope to continue to add new features to it so that it is useful for a wide range of analysis and scenarios. This guide documents the best way to make various types of contribution to TGX, including what is required before submitting a code change. Note that as the package evolves, this guideline will be improved as well, so feel free to check back here for more information in the near future too. </p> <p>Contributing to TGX is more than submitting code changes, we also welcome new research suggestions, inviting new users, testing releases and improving the documentation. Raising issues on Github to point out any issues or directions of improvement are also welcome. </p>"},{"location":"contribute/#reporting-issues-on-github","title":"Reporting issues on Github","text":"<p>Creating issues on Github is a useful way to manage problems and identify priorities. When possible, please add appropriate tags to the issue you are creating. For example, if it is related to the documentation website or error in documentation, you can include the <code>documentation</code> tag. If it is related to package installation, you can add the <code>install</code> tag. Overall, combining multiple issues that are related into a single one to report is also helpful to avoid trackig too many issues. </p>"},{"location":"contribute/#bugs","title":"Bugs","text":"<p>Bug reports are useful when they are accompanied by ways to understand and reproduce the bug. When reporting a bug, try to include detailed steps on how you encountered the bug and how to reproduce it. If you would like to propose a fix to the bug, feel free to link it to a pull request on the issue as well.</p>"},{"location":"contribute/#feedbacks-and-improvements","title":"Feedbacks and Improvements","text":"<p>Feedbacks and improvements on TGX are welcome. If you would like to see new temporal graph statistics or visualization added, feel free to reach out directly by email or create an issue on Github. You are of course more than welcome to add visualization and statistics from your own paper as well. </p>"},{"location":"contribute/#preparing-code-changes","title":"Preparing code changes","text":"<p>If you are interested in adding new features or fixing bugs in TGX, thanks for your help. This section walks you through on how to propose code changes to TGX. </p>"},{"location":"contribute/#deciding-what-to-work-on","title":"Deciding what to work on","text":"<p>The first step is to decide on which aspects you want to improve for TGX. The best way is to look at currently active issues on Github. You can find the future improvements we are planning in the Roadmap, from there you can find detailed instructions on what each task means. You are also very welcome to fix any bugs that you encounters or someone else encounters by proposing pull request on the github. Once you have decided on what you want to fix, reach out to us on TG slack (check the most recent link to join on the TG website) or by email and let's work on it together. </p>"},{"location":"contribute/#setting-up-dev-environment","title":"setting up dev environment","text":"<p>First, identify the issue you want to solve and create a new branch linked to the issue. (see create a branch button on right side of the issue.) Install TGX to the latest version as instructed below.</p> <ol> <li>Set up virtual environment (conda should work as well).</li> </ol> <pre><code>python -m venv tgx_env/\nsource tgx_env/bin/activate\n</code></pre> <ol> <li>Upgrade pip (Optional)</li> </ol> <pre><code>pip install --upgrade pip\n</code></pre> <ol> <li>Install external packages</li> </ol> <pre><code>pip install -r requirements.txt\n</code></pre> <ol> <li>Install local dependencies under root directory <code>/TGX</code>.</li> </ol> <pre><code>pip install -e .\n</code></pre> <ol> <li>Install <code>mkdocs</code> dependencies to serve the documentation locally. </li> </ol> <pre><code>pip install mkdocs mkdocs-material mkdocstrings-python mkdocs-glightbox mkdocs-jupyter ipython_genutils\n</code></pre> <ol> <li> <p>Switch to the branch you created from the issue (swap out <code>test</code> with name of your branch)     ```     git fetch origin</p> <p>git checkout -b test origin/test ```</p> </li> </ol>"},{"location":"contribute/#creating-pull-request","title":"Creating Pull Request","text":"<p>please make sure you have tested your code before creating a pull request, also created documentation for any new functions that you have added.  Once you created the pull request, you can reach out for a code review on slack or by email.</p>"},{"location":"classes/graph/","title":"Graph","text":""},{"location":"classes/graph/#graph","title":"Graph","text":""},{"location":"classes/graph/#tgx.classes.graph.Graph","title":"<code>Graph</code>","text":"<p>               Bases: <code>object</code></p> Source code in <code>tgx/classes/graph.py</code> <pre><code>class Graph(object):\n    def __init__(self, \n                 dataset: Optional[object] = None, \n                 fname: Optional[str] = None,\n                 edgelist: Optional[dict] = None):\n        \"\"\"\n        Create a Graph object with specific characteristics\n        Args:\n            dataset: a dataset object\n            edgelist: a dictionary of temporal edges in the form of {t: {(u, v), freq}}\n        \"\"\"\n\n        if dataset is not None:\n            if isinstance(dataset, type) or isinstance(dataset,object):\n                data = read_csv(dataset) \n        elif fname is not None and isinstance(fname, str):\n            data = read_csv(fname)\n        elif edgelist is not None and isinstance(edgelist, dict):\n            data = edgelist\n        else:\n            raise TypeError(\"Please enter valid input.\")\n\n        init_key = list(data.keys())[0]\n        if isinstance(data[init_key], list):\n            data = self._list2dict(data)\n        self.data = data\n        self.subsampled_graph = None\n        self.freq_data = None\n        self.id_map = None #a map from original node id to new node id based on their order of appearance\n\n    def _list2dict(self, data) -&gt; dict:\n        r\"\"\"\n        convert data into a dictionary of dictionary of temporal edges\n        \"\"\"\n        new_data = {}\n        for t in data.keys():\n            edgelist = {}\n            for u,v in data[t]:\n                edgelist[(u,v)] = 1\n            new_data[t] = edgelist\n        return new_data\n\n    #TODO support edge features, edge weights, node features and more, currently supports, timestamp, source, destination\n    def export_full_data(self):\n        \"\"\"\n        convert self.data inot a dictionary of numpy arrays similar to TGB LinkPropPredDataset\n        \"\"\"\n        num_edge = self.number_of_edges()\n        sources = np.zeros(num_edge, dtype=np.int64)\n        destinations = np.zeros(num_edge, dtype=np.int64)\n        timestamps = np.zeros(num_edge, dtype=np.int64)\n        idx = 0\n        edgelist = self.data\n\n        for ts, edge_data in edgelist.items():\n            for u,v in edge_data.keys():\n                sources[idx] = u\n                destinations[idx] = v\n                timestamps[idx] = ts\n                idx += 1\n        full_data = {\n            \"sources\": sources,\n            \"destinations\": destinations,\n            \"timestamps\": timestamps,\n        }\n        return full_data\n\n    def shift_time_to_zero(self) -&gt; None:\n        r\"\"\"\n        shift all edges in the dataset to start with timestamp 0\n        \"\"\"\n        min_t = list(self.data.keys())[0]\n        new_data = {}\n        for ts in self.data.keys():\n            new_data[ts - min_t] = self.data[ts]\n        self.data = new_data\n\n    def discretize(self, \n                   time_scale: Union[str, int],\n                   store_unix: bool = True,\n                   freq_weight: bool = False) -&gt; object:\n        \"\"\"\n        discretize the graph object based on the given time interval\n        Args:\n            time_scale: time interval to discretize the graph\n            store_unix: whether to store converted unix time in a list\n            freq_weight: whether to weight the edges by frequency in the new graph object\n        \"\"\"\n        new_G = copy.deepcopy(self)    \n        # discretie differently based on # of intervals of time granularity\n        output = discretize_edges(self.data,\n                                    time_scale = time_scale,\n                                    store_unix = store_unix,\n                                    freq_weight = freq_weight)\n        disc_G = output[0]\n        new_G.data = disc_G\n        if (store_unix):\n            return new_G, output[1]\n        else:\n            return (new_G, None)\n\n    def count_freq(self):\n        self.freq_data = frequency_count(self.data)\n        return self\n\n    def subsampling(self, \n                    node_list: Optional[list] = [], \n                    random_selection: Optional[bool] = True, \n                    N: Optional[int] = None) -&gt; object:\n        new_G = copy.deepcopy(self) \n        new_G.data = subsampling(new_G, node_list = node_list, random_selection=random_selection, N=N)\n        return new_G\n\n    def number_of_edges(self) -&gt; int:\n        r\"\"\"\n        Calculate total number of nodes present in an edgelist\n        \"\"\"\n        edgelist = self.data\n        e_num = 0\n        for _, edges in edgelist.items():\n            e_num += len(edges)\n\n        return e_num\n\n    def unique_edges(self) -&gt; int:\n        r\"\"\"\n        Calculate the number of unique edges\n        Parameters:\n        graph_edgelist: Dictionary containing graph data\n        \"\"\"\n        unique_edges = {}\n        for _, e_list in self.data.items():\n            for e in e_list:\n                if e not in unique_edges:\n                    unique_edges[e] = 1\n        return len(unique_edges)\n\n\n    def total_nodes(self) -&gt; int:\n        r\"\"\"\n        Calculate total number of unique nodes present in an edgelist\n        \"\"\"\n        edgelist = self.data\n        node_list = {}\n        for _, edge_data in edgelist.items():\n            for u,v in edge_data.keys():\n                if u not in node_list:\n                    node_list[u] = 1\n                if v not in node_list:\n                    node_list[v] = 1\n        return len(node_list)\n\n\n    def max_nid(self) -&gt; int:\n        r\"\"\"\n        find the largest node ID in the dataset\n        \"\"\"\n        edgelist = self.data\n        max_id = 0\n        for _, edge_data in edgelist.items():\n            for u,v in edge_data.keys():\n                if u &gt; max_id:\n                    max_id = u\n                if v &gt; max_id:\n                    max_id = v\n        return max_id #offset by 1\n\n    def min_nid(self) -&gt; int:\n        r\"\"\"\n        find the smallest node ID in the dataset\n        \"\"\"\n        edgelist = self.data\n        min_id = 1000000000\n        for _, edge_data in edgelist.items():\n            for u,v in edge_data.keys():\n                if u &lt; min_id:\n                    min_id = u\n                if v &lt; min_id:\n                    min_id = v\n        return min_id #offset by 1\n\n\n    def map_nid(self) -&gt; dict:\n        r\"\"\"\n        remap all node ids in the dataset to start from 0 and based on node order of appearance. Also updates self.data\n        Output: \n            id_map: a dictionary mapping original node id to new node id\n        \"\"\"\n        edgelist = self.data\n        id_map = {}\n        nid = 0\n        new_edgelist = {}\n        for ts, edge_data in edgelist.items():\n            new_edgelist[ts] = {}\n            for u,v in edge_data.keys():\n                if u not in id_map:\n                    id_map[u] = nid\n                    nid += 1\n                if v not in id_map:\n                    id_map[v] = nid\n                    nid += 1\n                new_edgelist[ts][(id_map[u],id_map[v])] = edge_data[(u,v)]\n        self.data = new_edgelist\n        return id_map\n\n\n    def node_per_ts(self):\n        active_nodes = {}\n        for ts in range(len(self.data)):\n            edgelist_t = self.data[ts]\n            active_nodes.append(self.edgelist_node_count(edgelist_t))\n        return active_nodes\n\n    def edgelist_node_count(self, edge_data: list):\n        node_list = {}\n        for edge in edge_data:\n            (u, v) = edge\n            if u not in node_list:\n                node_list[u] = 1\n            if v not in node_list:\n                node_list[v] = 1\n        return len(node_list.keys())\n\n    def edgelist_node_list(self, edge_data: list):\n        node_list = {}\n        for edge in edge_data:\n            (u, v) = edge\n            if u not in node_list:\n                node_list[u] = 1\n            if v not in node_list:\n                node_list[v] = 1\n        return list(node_list.keys())\n\n    def nodes_list(self) -&gt; list:\n        r\"\"\"\n        Return a list of nodes present in an edgelist\n        \"\"\"\n        node_list = {}\n        edgelist = self.data\n        for _, edge_data in edgelist.items():\n            for u,v in edge_data.keys():\n                if u not in node_list:\n                    node_list[u] = 1\n                if v not in node_list:\n                    node_list[v] = 1\n        self.node_list = list(node_list.keys())\n        return list(node_list.keys())\n\n    def check_time_gap(self) -&gt; bool:\n        r\"\"\"\n        Check whether the edgelist timestamps have gaps or not (increments bigger than 1)\n        Returns:\n            time_gap: a boolean indicating whether there is a time gap or not\n        \"\"\"\n        time_gap = False\n        ts = list(self.data.keys())\n        for i in range(1, len(ts)):\n            if ts[i] - ts[i-1] &gt; 1:\n                time_gap = True\n                return time_gap\n        return time_gap\n\n    def save2csv(self,\n                 fname:str = \"output\") -&gt; None:\n        r\"\"\"\n        Save the graph object in an edgelist format to a csv file\n        Args:\n            fname: name of the csv file to save the graph, no csv suffix needed\n        \"\"\"\n        outname = fname + \".csv\"\n        #iterate through all edges\n        with open(outname, 'w') as csvfile:\n            print (\"saving to \", outname)\n            csvwriter = csv.writer(csvfile, delimiter=',')\n            csvwriter.writerow(['timestamp'] + ['source'] + ['destination'])\n            for t, edges_list in self.data.items():\n                for edge in edges_list:\n                    (u, v) = edge\n                    csvwriter.writerow([t] + [u] + [v])        \n</code></pre>"},{"location":"classes/graph/#tgx.classes.graph.Graph.__init__","title":"<code>__init__(dataset=None, fname=None, edgelist=None)</code>","text":"<p>Create a Graph object with specific characteristics Args:     dataset: a dataset object     edgelist: a dictionary of temporal edges in the form of {t: {(u, v), freq}}</p> Source code in <code>tgx/classes/graph.py</code> <pre><code>def __init__(self, \n             dataset: Optional[object] = None, \n             fname: Optional[str] = None,\n             edgelist: Optional[dict] = None):\n    \"\"\"\n    Create a Graph object with specific characteristics\n    Args:\n        dataset: a dataset object\n        edgelist: a dictionary of temporal edges in the form of {t: {(u, v), freq}}\n    \"\"\"\n\n    if dataset is not None:\n        if isinstance(dataset, type) or isinstance(dataset,object):\n            data = read_csv(dataset) \n    elif fname is not None and isinstance(fname, str):\n        data = read_csv(fname)\n    elif edgelist is not None and isinstance(edgelist, dict):\n        data = edgelist\n    else:\n        raise TypeError(\"Please enter valid input.\")\n\n    init_key = list(data.keys())[0]\n    if isinstance(data[init_key], list):\n        data = self._list2dict(data)\n    self.data = data\n    self.subsampled_graph = None\n    self.freq_data = None\n    self.id_map = None #a map from original node id to new node id based on their order of appearance\n</code></pre>"},{"location":"classes/graph/#tgx.classes.graph.Graph.check_time_gap","title":"<code>check_time_gap()</code>","text":"<p>Check whether the edgelist timestamps have gaps or not (increments bigger than 1) Returns:     time_gap: a boolean indicating whether there is a time gap or not</p> Source code in <code>tgx/classes/graph.py</code> <pre><code>def check_time_gap(self) -&gt; bool:\n    r\"\"\"\n    Check whether the edgelist timestamps have gaps or not (increments bigger than 1)\n    Returns:\n        time_gap: a boolean indicating whether there is a time gap or not\n    \"\"\"\n    time_gap = False\n    ts = list(self.data.keys())\n    for i in range(1, len(ts)):\n        if ts[i] - ts[i-1] &gt; 1:\n            time_gap = True\n            return time_gap\n    return time_gap\n</code></pre>"},{"location":"classes/graph/#tgx.classes.graph.Graph.discretize","title":"<code>discretize(time_scale, store_unix=True, freq_weight=False)</code>","text":"<p>discretize the graph object based on the given time interval Args:     time_scale: time interval to discretize the graph     store_unix: whether to store converted unix time in a list     freq_weight: whether to weight the edges by frequency in the new graph object</p> Source code in <code>tgx/classes/graph.py</code> <pre><code>def discretize(self, \n               time_scale: Union[str, int],\n               store_unix: bool = True,\n               freq_weight: bool = False) -&gt; object:\n    \"\"\"\n    discretize the graph object based on the given time interval\n    Args:\n        time_scale: time interval to discretize the graph\n        store_unix: whether to store converted unix time in a list\n        freq_weight: whether to weight the edges by frequency in the new graph object\n    \"\"\"\n    new_G = copy.deepcopy(self)    \n    # discretie differently based on # of intervals of time granularity\n    output = discretize_edges(self.data,\n                                time_scale = time_scale,\n                                store_unix = store_unix,\n                                freq_weight = freq_weight)\n    disc_G = output[0]\n    new_G.data = disc_G\n    if (store_unix):\n        return new_G, output[1]\n    else:\n        return (new_G, None)\n</code></pre>"},{"location":"classes/graph/#tgx.classes.graph.Graph.export_full_data","title":"<code>export_full_data()</code>","text":"<p>convert self.data inot a dictionary of numpy arrays similar to TGB LinkPropPredDataset</p> Source code in <code>tgx/classes/graph.py</code> <pre><code>def export_full_data(self):\n    \"\"\"\n    convert self.data inot a dictionary of numpy arrays similar to TGB LinkPropPredDataset\n    \"\"\"\n    num_edge = self.number_of_edges()\n    sources = np.zeros(num_edge, dtype=np.int64)\n    destinations = np.zeros(num_edge, dtype=np.int64)\n    timestamps = np.zeros(num_edge, dtype=np.int64)\n    idx = 0\n    edgelist = self.data\n\n    for ts, edge_data in edgelist.items():\n        for u,v in edge_data.keys():\n            sources[idx] = u\n            destinations[idx] = v\n            timestamps[idx] = ts\n            idx += 1\n    full_data = {\n        \"sources\": sources,\n        \"destinations\": destinations,\n        \"timestamps\": timestamps,\n    }\n    return full_data\n</code></pre>"},{"location":"classes/graph/#tgx.classes.graph.Graph.map_nid","title":"<code>map_nid()</code>","text":"<p>remap all node ids in the dataset to start from 0 and based on node order of appearance. Also updates self.data Output:      id_map: a dictionary mapping original node id to new node id</p> Source code in <code>tgx/classes/graph.py</code> <pre><code>def map_nid(self) -&gt; dict:\n    r\"\"\"\n    remap all node ids in the dataset to start from 0 and based on node order of appearance. Also updates self.data\n    Output: \n        id_map: a dictionary mapping original node id to new node id\n    \"\"\"\n    edgelist = self.data\n    id_map = {}\n    nid = 0\n    new_edgelist = {}\n    for ts, edge_data in edgelist.items():\n        new_edgelist[ts] = {}\n        for u,v in edge_data.keys():\n            if u not in id_map:\n                id_map[u] = nid\n                nid += 1\n            if v not in id_map:\n                id_map[v] = nid\n                nid += 1\n            new_edgelist[ts][(id_map[u],id_map[v])] = edge_data[(u,v)]\n    self.data = new_edgelist\n    return id_map\n</code></pre>"},{"location":"classes/graph/#tgx.classes.graph.Graph.max_nid","title":"<code>max_nid()</code>","text":"<p>find the largest node ID in the dataset</p> Source code in <code>tgx/classes/graph.py</code> <pre><code>def max_nid(self) -&gt; int:\n    r\"\"\"\n    find the largest node ID in the dataset\n    \"\"\"\n    edgelist = self.data\n    max_id = 0\n    for _, edge_data in edgelist.items():\n        for u,v in edge_data.keys():\n            if u &gt; max_id:\n                max_id = u\n            if v &gt; max_id:\n                max_id = v\n    return max_id #offset by 1\n</code></pre>"},{"location":"classes/graph/#tgx.classes.graph.Graph.min_nid","title":"<code>min_nid()</code>","text":"<p>find the smallest node ID in the dataset</p> Source code in <code>tgx/classes/graph.py</code> <pre><code>def min_nid(self) -&gt; int:\n    r\"\"\"\n    find the smallest node ID in the dataset\n    \"\"\"\n    edgelist = self.data\n    min_id = 1000000000\n    for _, edge_data in edgelist.items():\n        for u,v in edge_data.keys():\n            if u &lt; min_id:\n                min_id = u\n            if v &lt; min_id:\n                min_id = v\n    return min_id #offset by 1\n</code></pre>"},{"location":"classes/graph/#tgx.classes.graph.Graph.nodes_list","title":"<code>nodes_list()</code>","text":"<p>Return a list of nodes present in an edgelist</p> Source code in <code>tgx/classes/graph.py</code> <pre><code>def nodes_list(self) -&gt; list:\n    r\"\"\"\n    Return a list of nodes present in an edgelist\n    \"\"\"\n    node_list = {}\n    edgelist = self.data\n    for _, edge_data in edgelist.items():\n        for u,v in edge_data.keys():\n            if u not in node_list:\n                node_list[u] = 1\n            if v not in node_list:\n                node_list[v] = 1\n    self.node_list = list(node_list.keys())\n    return list(node_list.keys())\n</code></pre>"},{"location":"classes/graph/#tgx.classes.graph.Graph.number_of_edges","title":"<code>number_of_edges()</code>","text":"<p>Calculate total number of nodes present in an edgelist</p> Source code in <code>tgx/classes/graph.py</code> <pre><code>def number_of_edges(self) -&gt; int:\n    r\"\"\"\n    Calculate total number of nodes present in an edgelist\n    \"\"\"\n    edgelist = self.data\n    e_num = 0\n    for _, edges in edgelist.items():\n        e_num += len(edges)\n\n    return e_num\n</code></pre>"},{"location":"classes/graph/#tgx.classes.graph.Graph.save2csv","title":"<code>save2csv(fname='output')</code>","text":"<p>Save the graph object in an edgelist format to a csv file Args:     fname: name of the csv file to save the graph, no csv suffix needed</p> Source code in <code>tgx/classes/graph.py</code> <pre><code>def save2csv(self,\n             fname:str = \"output\") -&gt; None:\n    r\"\"\"\n    Save the graph object in an edgelist format to a csv file\n    Args:\n        fname: name of the csv file to save the graph, no csv suffix needed\n    \"\"\"\n    outname = fname + \".csv\"\n    #iterate through all edges\n    with open(outname, 'w') as csvfile:\n        print (\"saving to \", outname)\n        csvwriter = csv.writer(csvfile, delimiter=',')\n        csvwriter.writerow(['timestamp'] + ['source'] + ['destination'])\n        for t, edges_list in self.data.items():\n            for edge in edges_list:\n                (u, v) = edge\n                csvwriter.writerow([t] + [u] + [v])        \n</code></pre>"},{"location":"classes/graph/#tgx.classes.graph.Graph.shift_time_to_zero","title":"<code>shift_time_to_zero()</code>","text":"<p>shift all edges in the dataset to start with timestamp 0</p> Source code in <code>tgx/classes/graph.py</code> <pre><code>def shift_time_to_zero(self) -&gt; None:\n    r\"\"\"\n    shift all edges in the dataset to start with timestamp 0\n    \"\"\"\n    min_t = list(self.data.keys())[0]\n    new_data = {}\n    for ts in self.data.keys():\n        new_data[ts - min_t] = self.data[ts]\n    self.data = new_data\n</code></pre>"},{"location":"classes/graph/#tgx.classes.graph.Graph.total_nodes","title":"<code>total_nodes()</code>","text":"<p>Calculate total number of unique nodes present in an edgelist</p> Source code in <code>tgx/classes/graph.py</code> <pre><code>def total_nodes(self) -&gt; int:\n    r\"\"\"\n    Calculate total number of unique nodes present in an edgelist\n    \"\"\"\n    edgelist = self.data\n    node_list = {}\n    for _, edge_data in edgelist.items():\n        for u,v in edge_data.keys():\n            if u not in node_list:\n                node_list[u] = 1\n            if v not in node_list:\n                node_list[v] = 1\n    return len(node_list)\n</code></pre>"},{"location":"classes/graph/#tgx.classes.graph.Graph.unique_edges","title":"<code>unique_edges()</code>","text":"<p>Calculate the number of unique edges Parameters: graph_edgelist: Dictionary containing graph data</p> Source code in <code>tgx/classes/graph.py</code> <pre><code>def unique_edges(self) -&gt; int:\n    r\"\"\"\n    Calculate the number of unique edges\n    Parameters:\n    graph_edgelist: Dictionary containing graph data\n    \"\"\"\n    unique_edges = {}\n    for _, e_list in self.data.items():\n        for e in e_list:\n            if e not in unique_edges:\n                unique_edges[e] = 1\n    return len(unique_edges)\n</code></pre>"},{"location":"data/builtin/","title":"Builtin","text":""},{"location":"data/builtin/#builtin-datasets","title":"Builtin Datasets","text":""},{"location":"data/builtin/#tgx.data.builtin.builtin","title":"<code>builtin</code>","text":"<p>               Bases: <code>object</code></p> Source code in <code>tgx/data/builtin.py</code> <pre><code>class builtin(object):\n    def __init__(self):\n        \"\"\"\n        Data class for loading default (in-package) temporal datasets\n\n        In order to use \"tgb\" datasets install tgb package\n        for more detals visit here: https://tgb.complexdatalab.com/\n\n        In order to use dgb datasets download and extract dataset file\n        from here: https://zenodo.org/record/7213796#.Y1cO6y8r30o\n        and locate them in ./data/ directory.\n        \"\"\"\n        pass\n\n\n    def read_specifications(self, \n                            data: type):\n        \"\"\"\n        Load dataset specifications for dgb datasets\n        Parameters:\n            data: str, name of the dataset\n        \"\"\"\n        self.name = data\n        self.path = DataPath[data]\n        # self.header = Data_specifications[data]['header']\n        # self.index = Data_specifications[data]['index']\n        self.discretize = Data_specifications[data]['discretize']\n        self.time_scale = Data_specifications[data]['time_scale']\n        return self\n\n    def load_dgb_data(self):\n        try:\n            data = pd.read_csv(f\"{self.root}{self.path}\", index_col=0)\n        except:\n            self.download_file(self)\n            data = pd.read_csv(f\"{self.root}{self.path}\", index_col=0)\n\n        self.data =  data.iloc[:, 0:3].to_numpy()\n        return self\n\n    def download_file(self):\n\n        print(\"Data missing, download recommended!\")\n        inp = input('Will you download the dataset(s) now? (y/N)\\n').lower()\n        url = f\"https://zenodo.org/record/7213796/files/{self.name}.zip\"\n        path_download = f\"./data\" \n        print(path_download)\n        print(url)\n        if inp == 'y':\n            if not os.path.exists(path_download):\n                os.mkdir(path_download)\n                print(\"Folder %s created!\" % path_download)\n\n            print(f\"Downloading {self.name} dataset . . .\")\n            zip_path = download(url, path_download)\n            with zipfile.ZipFile(zip_path, \"r\") as f:\n                f.extractall(path_download)\n            print(\"Download completed\")\n\n        else:\n            print(\"Download cancelled\")\n\n\n    @classmethod\n    def mooc(self, root=root_path):\n        data = \"mooc\"\n        self.root = root\n        self.read_specifications(self, data)\n        self.load_dgb_data(self)\n        return self\n\n    @classmethod\n    def uci(self, root=root_path):\n        data = \"uci\"\n        self.root = root\n        self.read_specifications(self, data)\n        self.load_dgb_data(self)\n        return self\n\n    @classmethod   \n    def uslegis(self, root=root_path):\n        data = \"USLegis\"\n        self.root = root\n        self.read_specifications(self, data)\n        self.load_dgb_data(self)\n        return self\n\n    @classmethod\n    def canparl(self, root=root_path):\n        data = \"CanParl\"\n        self.root = root\n        self.read_specifications(self, data)\n        self.load_dgb_data(self)\n        return self\n\n    @classmethod\n    def untrade(self, root=root_path):\n        data = \"UNtrade\"\n        self.root = root\n        self.read_specifications(self, data)\n        self.load_dgb_data(self)\n        return self\n\n    @classmethod\n    def unvote(self, root=root_path):\n        data = \"UNvote\"\n        self.root = root\n        self.read_specifications(self, data)\n        self.load_dgb_data(self)\n        return self\n\n    @classmethod\n    def reddit(self, root=root_path):\n        data = \"reddit\"\n        self.root = root\n        self.read_specifications(self, data)\n        self.load_dgb_data(self)\n        return self\n\n    @classmethod\n    def wikipedia(self, root=root_path):\n        data = \"Wikipedia\"\n        self.root = root\n        self.read_specifications(self, data)\n        self.load_dgb_data(self)\n        return self\n\n    @classmethod\n    def enron(self, root=root_path):\n        data = \"enron\"\n        self.root = root\n        self.read_specifications(self, data)\n        self.load_dgb_data(self)\n        return self\n\n    @classmethod\n    def social_evo(self, root=root_path):\n        data = \"SocialEvo\"\n        self.root = root\n        self.read_specifications(self, data)\n        self.load_dgb_data(self)\n        return self\n\n    @classmethod\n    def flights(self, root=root_path):\n        data = \"Flights\"\n        self.root = root\n        self.read_specifications(self, data)\n        self.load_dgb_data(self)\n        return self\n\n    @classmethod\n    def lastfm(self, root=root_path):\n        data = \"lastfm\"\n        self.root = root\n        self.read_specifications(self, data)\n        self.load_dgb_data(self)\n        return self\n\n    @classmethod\n    def contacts(self, root=root_path):\n        data = \"Contacts\"\n        self.root = root\n        self.read_specifications(self, data)\n        self.load_dgb_data(self)\n        return self\n</code></pre>"},{"location":"data/builtin/#tgx.data.builtin.builtin.__init__","title":"<code>__init__()</code>","text":"<p>Data class for loading default (in-package) temporal datasets</p> <p>In order to use \"tgb\" datasets install tgb package for more detals visit here: https://tgb.complexdatalab.com/</p> <p>In order to use dgb datasets download and extract dataset file from here: https://zenodo.org/record/7213796#.Y1cO6y8r30o and locate them in ./data/ directory.</p> Source code in <code>tgx/data/builtin.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Data class for loading default (in-package) temporal datasets\n\n    In order to use \"tgb\" datasets install tgb package\n    for more detals visit here: https://tgb.complexdatalab.com/\n\n    In order to use dgb datasets download and extract dataset file\n    from here: https://zenodo.org/record/7213796#.Y1cO6y8r30o\n    and locate them in ./data/ directory.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"data/builtin/#tgx.data.builtin.builtin.read_specifications","title":"<code>read_specifications(data)</code>","text":"<p>Load dataset specifications for dgb datasets Parameters:     data: str, name of the dataset</p> Source code in <code>tgx/data/builtin.py</code> <pre><code>def read_specifications(self, \n                        data: type):\n    \"\"\"\n    Load dataset specifications for dgb datasets\n    Parameters:\n        data: str, name of the dataset\n    \"\"\"\n    self.name = data\n    self.path = DataPath[data]\n    # self.header = Data_specifications[data]['header']\n    # self.index = Data_specifications[data]['index']\n    self.discretize = Data_specifications[data]['discretize']\n    self.time_scale = Data_specifications[data]['time_scale']\n    return self\n</code></pre>"},{"location":"data/tgb/","title":"TGB","text":""},{"location":"data/tgb/#tgb-datasets","title":"TGB Datasets","text":""},{"location":"data/tgb/#tgx.data.tgb.tgb_data","title":"<code>tgb_data</code>","text":"<p>               Bases: <code>object</code></p> Source code in <code>tgx/data/tgb.py</code> <pre><code>class tgb_data(object):\n    def __init__(self, dname: str, \n            edge_feat: bool = False,\n            w: bool = False,\n            edge_label: bool = False,\n            edge_idxs: bool = False):\n        \"\"\"\n        Data class for loading default (in-package) temporal datasets\n\n        In order to use \"tgb\" datasets install tgb package\n        for more detals visit here: https://tgb.complexdatalab.com/\n\n        In order to use dgb datasets download and extract dataset file\n        from here: https://zenodo.org/record/7213796#.Y1cO6y8r30o\n        and locate them in ./data/ directory.\n        \"\"\"\n        self.tgb(dname, \n                edge_feat = edge_feat,\n                w = w,\n                edge_label = edge_label,\n                edge_idxs = edge_idxs)\n\n        return\n\n    @classmethod\n    def tgb(self, dname: str, \n            edge_feat: bool = False,\n            w: bool = False,\n            edge_label: bool = False,\n            edge_idxs: bool = False):\n        \"\"\"\n        Load datasets from \"tgb\" package. To load these datasets you need to install tgb package.\n        Parameters:\n            dname: str, name of the dataset from the list:\n                        [\"tgbl-wiki\", \"tgbl-review\", \n                        \"tgbl-coin\", \"tgbl-comment\", \n                        \"tgbl-flight\",\"tgbn-trade\", \n                        \"tgbn-genre\", \"tgbn-reddit\"]\n            edge_feat: list of edge features\n            w: edge weights\n            edge_label: edge labels\n            edge_idxs: edge indexes\n\n        \"\"\"\n        try:\n            from tgb.linkproppred.dataset import LinkPropPredDataset\n            from tgb.nodeproppred.dataset import NodePropPredDataset\n        except:\n            print(\"First install TGB package using 'pip install py-tgb'\")\n\n        #TODO not hard code the dataset name anymore\n        link_pred = [\"tgbl-wiki\", \"tgbl-review\", \"tgbl-coin\", \"tgbl-comment\", \"tgbl-flight\"]\n        node_pred = [\"tgbn-trade\", \"tgbn-genre\", \"tgbn-reddit\", \"tgbn-token\"]\n        if dname in link_pred:\n            dataset = LinkPropPredDataset(name=dname, root=\"datasets\", preprocess=True)\n        elif dname in node_pred:\n            dataset = NodePropPredDataset(name=dname, root=\"datasets\", preprocess=True)\n        else:\n            raise ValueError(\"Invalid tgb dataset name\")\n\n        data = dataset.full_data\n        data = np.array([data['sources'], data[\"destinations\"], data[\"timestamps\"]])\n        self.data = np.transpose(data)\n\n        if edge_feat:\n            self.edge_feat = data['edge_feat']\n        if w:\n            self.w = data['w']\n        if edge_label:\n            self.edge_label = data['edge_label']\n        if edge_idxs:\n            self.edge_idxs = data['edge_idxs']\n\n        self.discretize = Data_specifications[dname]['discretize']\n        self.time_scale = Data_specifications[dname]['time_scale']\n        self.train_mask = dataset.train_mask\n        self.val_mask = dataset.val_mask\n        self.test_mask = dataset.test_mask\n        self.name = dname\n\n        return self\n\n\n    def read_specifications(self, \n                            data: type):\n        \"\"\"\n        Load dataset specifications for dgb datasets\n        Parameters:\n            data: str, name of the dataset\n        \"\"\"\n        self.name = data\n        self.discretize = Data_specifications[data]['discretize']\n        self.time_scale = Data_specifications[data]['time_scale']\n        return self\n</code></pre>"},{"location":"data/tgb/#tgx.data.tgb.tgb_data.__init__","title":"<code>__init__(dname, edge_feat=False, w=False, edge_label=False, edge_idxs=False)</code>","text":"<p>Data class for loading default (in-package) temporal datasets</p> <p>In order to use \"tgb\" datasets install tgb package for more detals visit here: https://tgb.complexdatalab.com/</p> <p>In order to use dgb datasets download and extract dataset file from here: https://zenodo.org/record/7213796#.Y1cO6y8r30o and locate them in ./data/ directory.</p> Source code in <code>tgx/data/tgb.py</code> <pre><code>def __init__(self, dname: str, \n        edge_feat: bool = False,\n        w: bool = False,\n        edge_label: bool = False,\n        edge_idxs: bool = False):\n    \"\"\"\n    Data class for loading default (in-package) temporal datasets\n\n    In order to use \"tgb\" datasets install tgb package\n    for more detals visit here: https://tgb.complexdatalab.com/\n\n    In order to use dgb datasets download and extract dataset file\n    from here: https://zenodo.org/record/7213796#.Y1cO6y8r30o\n    and locate them in ./data/ directory.\n    \"\"\"\n    self.tgb(dname, \n            edge_feat = edge_feat,\n            w = w,\n            edge_label = edge_label,\n            edge_idxs = edge_idxs)\n\n    return\n</code></pre>"},{"location":"data/tgb/#tgx.data.tgb.tgb_data.read_specifications","title":"<code>read_specifications(data)</code>","text":"<p>Load dataset specifications for dgb datasets Parameters:     data: str, name of the dataset</p> Source code in <code>tgx/data/tgb.py</code> <pre><code>def read_specifications(self, \n                        data: type):\n    \"\"\"\n    Load dataset specifications for dgb datasets\n    Parameters:\n        data: str, name of the dataset\n    \"\"\"\n    self.name = data\n    self.discretize = Data_specifications[data]['discretize']\n    self.time_scale = Data_specifications[data]['time_scale']\n    return self\n</code></pre>"},{"location":"data/tgb/#tgx.data.tgb.tgb_data.tgb","title":"<code>tgb(dname, edge_feat=False, w=False, edge_label=False, edge_idxs=False)</code>  <code>classmethod</code>","text":"<p>Load datasets from \"tgb\" package. To load these datasets you need to install tgb package. Parameters:     dname: str, name of the dataset from the list:                 [\"tgbl-wiki\", \"tgbl-review\",                  \"tgbl-coin\", \"tgbl-comment\",                  \"tgbl-flight\",\"tgbn-trade\",                  \"tgbn-genre\", \"tgbn-reddit\"]     edge_feat: list of edge features     w: edge weights     edge_label: edge labels     edge_idxs: edge indexes</p> Source code in <code>tgx/data/tgb.py</code> <pre><code>@classmethod\ndef tgb(self, dname: str, \n        edge_feat: bool = False,\n        w: bool = False,\n        edge_label: bool = False,\n        edge_idxs: bool = False):\n    \"\"\"\n    Load datasets from \"tgb\" package. To load these datasets you need to install tgb package.\n    Parameters:\n        dname: str, name of the dataset from the list:\n                    [\"tgbl-wiki\", \"tgbl-review\", \n                    \"tgbl-coin\", \"tgbl-comment\", \n                    \"tgbl-flight\",\"tgbn-trade\", \n                    \"tgbn-genre\", \"tgbn-reddit\"]\n        edge_feat: list of edge features\n        w: edge weights\n        edge_label: edge labels\n        edge_idxs: edge indexes\n\n    \"\"\"\n    try:\n        from tgb.linkproppred.dataset import LinkPropPredDataset\n        from tgb.nodeproppred.dataset import NodePropPredDataset\n    except:\n        print(\"First install TGB package using 'pip install py-tgb'\")\n\n    #TODO not hard code the dataset name anymore\n    link_pred = [\"tgbl-wiki\", \"tgbl-review\", \"tgbl-coin\", \"tgbl-comment\", \"tgbl-flight\"]\n    node_pred = [\"tgbn-trade\", \"tgbn-genre\", \"tgbn-reddit\", \"tgbn-token\"]\n    if dname in link_pred:\n        dataset = LinkPropPredDataset(name=dname, root=\"datasets\", preprocess=True)\n    elif dname in node_pred:\n        dataset = NodePropPredDataset(name=dname, root=\"datasets\", preprocess=True)\n    else:\n        raise ValueError(\"Invalid tgb dataset name\")\n\n    data = dataset.full_data\n    data = np.array([data['sources'], data[\"destinations\"], data[\"timestamps\"]])\n    self.data = np.transpose(data)\n\n    if edge_feat:\n        self.edge_feat = data['edge_feat']\n    if w:\n        self.w = data['w']\n    if edge_label:\n        self.edge_label = data['edge_label']\n    if edge_idxs:\n        self.edge_idxs = data['edge_idxs']\n\n    self.discretize = Data_specifications[dname]['discretize']\n    self.time_scale = Data_specifications[dname]['time_scale']\n    self.train_mask = dataset.train_mask\n    self.val_mask = dataset.val_mask\n    self.test_mask = dataset.test_mask\n    self.name = dname\n\n    return self\n</code></pre>"},{"location":"gallery/0-degree-builtin/","title":"Plot by type","text":""},{"location":"gallery/0-degree-builtin/#tea-plots","title":"TEA plots","text":""},{"location":"gallery/0-degree-builtin/#reddit","title":"Reddit","text":""},{"location":"gallery/0-degree-builtin/#mooc","title":"MOOC","text":""},{"location":"gallery/0-degree-builtin/#lastfm","title":"LastFM","text":""},{"location":"gallery/0-degree-builtin/#enron","title":"Enron","text":""},{"location":"gallery/0-degree-builtin/#social-evo","title":"Social Evo","text":""},{"location":"gallery/0-degree-builtin/#uci","title":"UCI","text":""},{"location":"gallery/0-degree-builtin/#flights","title":"Flights","text":""},{"location":"gallery/0-degree-builtin/#can-parl","title":"Can. Parl.","text":""},{"location":"gallery/0-degree-builtin/#us-legis","title":"US Legis","text":""},{"location":"gallery/0-degree-builtin/#un-vote","title":"UN Vote","text":""},{"location":"gallery/0-degree-builtin/#contacts","title":"Contacts","text":""},{"location":"gallery/0-degree-tgb/","title":"Plot by type","text":""},{"location":"gallery/0-degree-tgb/#tea-plots","title":"TEA plots","text":""},{"location":"gallery/0-degree-tgb/#tgbl-wiki","title":"tgbl-wiki","text":""},{"location":"gallery/0-degree-tgb/#tgbl-review","title":"tgbl-review","text":""},{"location":"gallery/0-degree-tgb/#tgbl-coin","title":"tgbl-coin","text":""},{"location":"gallery/0-degree-tgb/#tgbl-comment","title":"tgbl-comment","text":""},{"location":"gallery/0-degree-tgb/#tgbl-flight","title":"tgbl-flight","text":""},{"location":"gallery/0-degree-tgb/#tgbn-trade","title":"tgbn-trade","text":""},{"location":"gallery/0-degree-tgb/#tgbn-genre","title":"tgbn-genre","text":""},{"location":"gallery/0-degree-tgb/#tgbn-reddit","title":"tgbn-reddit","text":""},{"location":"gallery/0-node_edge-builtin/","title":"Plot by type","text":""},{"location":"gallery/0-node_edge-builtin/#tea-plots","title":"TEA plots","text":""},{"location":"gallery/0-node_edge-builtin/#reddit","title":"Reddit","text":""},{"location":"gallery/0-node_edge-builtin/#mooc","title":"MOOC","text":""},{"location":"gallery/0-node_edge-builtin/#lastfm","title":"LastFM","text":""},{"location":"gallery/0-node_edge-builtin/#enron","title":"Enron","text":""},{"location":"gallery/0-node_edge-builtin/#social-evo","title":"Social Evo","text":""},{"location":"gallery/0-node_edge-builtin/#uci","title":"UCI","text":""},{"location":"gallery/0-node_edge-builtin/#flights","title":"Flights","text":""},{"location":"gallery/0-node_edge-builtin/#can-parl","title":"Can. Parl.","text":""},{"location":"gallery/0-node_edge-builtin/#us-legis","title":"US Legis","text":""},{"location":"gallery/0-node_edge-builtin/#un-vote","title":"UN Vote","text":""},{"location":"gallery/0-node_edge-builtin/#contacts","title":"Contacts","text":""},{"location":"gallery/0-node_edge-tgb/","title":"Plot by type","text":""},{"location":"gallery/0-node_edge-tgb/#tea-plots","title":"TEA plots","text":""},{"location":"gallery/0-node_edge-tgb/#tgbl-wiki","title":"tgbl-wiki","text":""},{"location":"gallery/0-node_edge-tgb/#tgbl-review","title":"tgbl-review","text":""},{"location":"gallery/0-node_edge-tgb/#tgbl-coin","title":"tgbl-coin","text":""},{"location":"gallery/0-node_edge-tgb/#tgbl-comment","title":"tgbl-comment","text":""},{"location":"gallery/0-node_edge-tgb/#tgbl-flight","title":"tgbl-flight","text":""},{"location":"gallery/0-node_edge-tgb/#tgbn-trade","title":"tgbn-trade","text":""},{"location":"gallery/0-node_edge-tgb/#tgbn-genre","title":"tgbn-genre","text":""},{"location":"gallery/0-node_edge-tgb/#tgbn-reddit","title":"tgbn-reddit","text":""},{"location":"gallery/0-tea-builtin/","title":"Plot by type","text":""},{"location":"gallery/0-tea-builtin/#tea-plots","title":"TEA plots","text":""},{"location":"gallery/0-tea-builtin/#reddit","title":"Reddit","text":""},{"location":"gallery/0-tea-builtin/#mooc","title":"MOOC","text":""},{"location":"gallery/0-tea-builtin/#lastfm","title":"LastFM","text":""},{"location":"gallery/0-tea-builtin/#enron","title":"Enron","text":""},{"location":"gallery/0-tea-builtin/#social-evo","title":"Social Evo","text":""},{"location":"gallery/0-tea-builtin/#uci","title":"UCI","text":""},{"location":"gallery/0-tea-builtin/#flights","title":"Flights","text":""},{"location":"gallery/0-tea-builtin/#can-parl","title":"Can. Parl.","text":""},{"location":"gallery/0-tea-builtin/#us-legis","title":"US Legis","text":""},{"location":"gallery/0-tea-builtin/#un-vote","title":"UN Vote","text":""},{"location":"gallery/0-tea-builtin/#contacts","title":"Contacts","text":""},{"location":"gallery/0-tea-tgb/","title":"Plot by type","text":""},{"location":"gallery/0-tea-tgb/#tgbl-wiki","title":"tgbl-wiki","text":""},{"location":"gallery/0-tea-tgb/#tgbl-review","title":"tgbl-review","text":""},{"location":"gallery/0-tea-tgb/#tgbl-coin","title":"tgbl-coin","text":""},{"location":"gallery/0-tea-tgb/#tgbl-comment","title":"tgbl-comment","text":""},{"location":"gallery/0-tea-tgb/#tgbl-flight","title":"tgbl-flight","text":""},{"location":"gallery/0-tea-tgb/#tgbn-trade","title":"tgbn-trade","text":""},{"location":"gallery/0-tea-tgb/#tgbn-genre","title":"tgbn-genre","text":""},{"location":"gallery/0-tea-tgb/#tgbn-reddit","title":"tgbn-reddit","text":""},{"location":"gallery/0-tet-builtin/","title":"Builtin","text":""},{"location":"gallery/0-tet-builtin/#tet-plots","title":"TET Plots","text":""},{"location":"gallery/0-tet-builtin/#reddit","title":"Reddit","text":""},{"location":"gallery/0-tet-builtin/#mooc","title":"MOOC","text":""},{"location":"gallery/0-tet-builtin/#lastfm","title":"LastFM","text":""},{"location":"gallery/0-tet-builtin/#enron","title":"Enron","text":""},{"location":"gallery/0-tet-builtin/#social-evo","title":"Social Evo","text":""},{"location":"gallery/0-tet-builtin/#uci","title":"UCI","text":""},{"location":"gallery/0-tet-builtin/#flights","title":"Flights","text":""},{"location":"gallery/0-tet-builtin/#can-parl","title":"Can. Parl.","text":""},{"location":"gallery/0-tet-builtin/#us-legis","title":"US Legis","text":""},{"location":"gallery/0-tet-builtin/#un-vote","title":"UN Vote","text":""},{"location":"gallery/0-tet-builtin/#contacts","title":"Contacts","text":""},{"location":"gallery/0-tet-tgb/","title":"TGB","text":""},{"location":"gallery/0-tet-tgb/#tet-plots","title":"TET Plots","text":""},{"location":"gallery/0-tet-tgb/#tgbl-wiki","title":"tgbl-wiki","text":""},{"location":"gallery/0-tet-tgb/#tgbl-review","title":"tgbl-review","text":""},{"location":"gallery/0-tet-tgb/#tgbl-coin","title":"tgbl-coin","text":""},{"location":"gallery/0-tet-tgb/#tgbl-comment","title":"tgbl-comment","text":""},{"location":"gallery/0-tet-tgb/#tgbl-flight","title":"tgbl-flight","text":""},{"location":"gallery/0-tet-tgb/#tgbn-trade","title":"tgbn-trade","text":""},{"location":"gallery/0-tet-tgb/#tgbn-genre","title":"tgbn-genre","text":""},{"location":"gallery/0-tet-tgb/#tgbn-reddit","title":"tgbn-reddit","text":""},{"location":"gallery/canparl/","title":"Can Parl","text":""},{"location":"gallery/canparl/#can-parl","title":"Can. Parl.","text":""},{"location":"gallery/canparl/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/canparl/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/canparl/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/canparl/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/contact/","title":"Contacts","text":""},{"location":"gallery/contact/#contacts","title":"Contacts","text":""},{"location":"gallery/contact/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/contact/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/contact/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/contact/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/dataset/","title":"Plot by dataset","text":""},{"location":"gallery/dataset/#reddit","title":"Reddit","text":""},{"location":"gallery/dataset/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/dataset/#mooc","title":"MOOC","text":""},{"location":"gallery/dataset/#tea-plot_1","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_1","title":"TET Plot","text":""},{"location":"gallery/dataset/#lastfm","title":"LastFM","text":""},{"location":"gallery/dataset/#tea-plot_2","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_2","title":"TET Plot","text":""},{"location":"gallery/dataset/#enron","title":"Enron","text":""},{"location":"gallery/dataset/#tea-plot_3","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_3","title":"TET Plot","text":""},{"location":"gallery/dataset/#social-evo","title":"Social Evo","text":""},{"location":"gallery/dataset/#tea-plot_4","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_4","title":"TET Plot","text":""},{"location":"gallery/dataset/#uci","title":"UCI","text":""},{"location":"gallery/dataset/#tea-plot_5","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_5","title":"TET Plot","text":""},{"location":"gallery/dataset/#flights","title":"Flights","text":""},{"location":"gallery/dataset/#tea-plot_6","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_6","title":"TET Plot","text":""},{"location":"gallery/dataset/#can-parl","title":"Can. Parl.","text":""},{"location":"gallery/dataset/#tea-plot_7","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_7","title":"TET Plot","text":""},{"location":"gallery/dataset/#us-legis","title":"US Legis","text":""},{"location":"gallery/dataset/#tea-plot_8","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_8","title":"TET Plot","text":""},{"location":"gallery/dataset/#un-vote","title":"UN Vote","text":""},{"location":"gallery/dataset/#tea-plot_9","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_9","title":"TET Plot","text":""},{"location":"gallery/dataset/#contacts","title":"Contacts","text":""},{"location":"gallery/dataset/#tea-plot_10","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_10","title":"TET Plot","text":""},{"location":"gallery/dataset/#tgbl-wiki","title":"tgbl-wiki","text":""},{"location":"gallery/dataset/#tea-plot_11","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_11","title":"TET Plot","text":""},{"location":"gallery/dataset/#tgbl-review","title":"tgbl-review","text":""},{"location":"gallery/dataset/#tea-plot_12","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_12","title":"TET Plot","text":""},{"location":"gallery/dataset/#tgbl-coin","title":"tgbl-coin","text":""},{"location":"gallery/dataset/#tea-plot_13","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_13","title":"TET Plot","text":""},{"location":"gallery/dataset/#tgbl-comment","title":"tgbl-comment","text":""},{"location":"gallery/dataset/#tea-plot_14","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_14","title":"TET Plot","text":""},{"location":"gallery/dataset/#tgbl-flight","title":"tgbl-flight","text":""},{"location":"gallery/dataset/#tea-plot_15","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_15","title":"TET Plot","text":""},{"location":"gallery/dataset/#tgbn-trade","title":"tgbn-trade","text":""},{"location":"gallery/dataset/#tea-plot_16","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_16","title":"TET Plot","text":""},{"location":"gallery/dataset/#tgbn-genre","title":"tgbn-genre","text":""},{"location":"gallery/dataset/#tea-plot_17","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_17","title":"TET Plot","text":""},{"location":"gallery/dataset/#tgbn-reddit","title":"tgbn-reddit","text":""},{"location":"gallery/dataset/#tea-plot_18","title":"TEA Plot","text":""},{"location":"gallery/dataset/#tet-plot_18","title":"TET Plot","text":""},{"location":"gallery/enron/","title":"Enron","text":""},{"location":"gallery/enron/#enron","title":"Enron","text":""},{"location":"gallery/enron/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/enron/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/enron/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/enron/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/flight/","title":"Flights","text":""},{"location":"gallery/flight/#flights","title":"Flights","text":""},{"location":"gallery/flight/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/flight/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/flight/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/flight/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/lastfm/","title":"LastFM","text":""},{"location":"gallery/lastfm/#lastfm","title":"LastFM","text":""},{"location":"gallery/lastfm/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/lastfm/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/lastfm/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/lastfm/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/mooc/","title":"MOOC","text":""},{"location":"gallery/mooc/#mooc","title":"MOOC","text":""},{"location":"gallery/mooc/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/mooc/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/mooc/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/mooc/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/reddit/","title":"Reddit","text":""},{"location":"gallery/reddit/#reddit","title":"Reddit","text":""},{"location":"gallery/reddit/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/reddit/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/reddit/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/reddit/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/socialevo/","title":"Social Evo","text":""},{"location":"gallery/socialevo/#social-evo","title":"Social Evo","text":""},{"location":"gallery/socialevo/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/socialevo/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/socialevo/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/socialevo/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/tgbl-coin/","title":"tgbl-coin","text":""},{"location":"gallery/tgbl-coin/#tgbl-coin","title":"tgbl-coin","text":""},{"location":"gallery/tgbl-coin/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/tgbl-coin/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/tgbl-coin/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/tgbl-coin/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/tgbl-comment/","title":"tgbl-comment","text":""},{"location":"gallery/tgbl-comment/#tgbl-comment","title":"tgbl-comment","text":""},{"location":"gallery/tgbl-comment/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/tgbl-comment/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/tgbl-comment/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/tgbl-comment/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/tgbl-flight/","title":"tgbl-flight","text":""},{"location":"gallery/tgbl-flight/#tgbl-flight","title":"tgbl-flight","text":""},{"location":"gallery/tgbl-flight/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/tgbl-flight/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/tgbl-flight/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/tgbl-flight/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/tgbl-review/","title":"tgbl-review","text":""},{"location":"gallery/tgbl-review/#tgbl-review","title":"tgbl-review","text":""},{"location":"gallery/tgbl-review/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/tgbl-review/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/tgbl-review/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/tgbl-review/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/tgbl-wiki/","title":"tgbl-wiki","text":""},{"location":"gallery/tgbl-wiki/#tgbl-wiki","title":"tgbl-wiki","text":""},{"location":"gallery/tgbl-wiki/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/tgbl-wiki/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/tgbl-wiki/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/tgbl-wiki/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/tgbn-genre/","title":"tgbn-genre","text":""},{"location":"gallery/tgbn-genre/#tgbn-genre","title":"tgbn-genre","text":""},{"location":"gallery/tgbn-genre/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/tgbn-genre/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/tgbn-genre/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/tgbn-genre/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/tgbn-reddit/","title":"tgbn-reddit","text":""},{"location":"gallery/tgbn-reddit/#tgbn-reddit","title":"tgbn-reddit","text":""},{"location":"gallery/tgbn-reddit/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/tgbn-reddit/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/tgbn-reddit/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/tgbn-reddit/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/tgbn-trade/","title":"tgbn-trade","text":""},{"location":"gallery/tgbn-trade/#tgbn-trade","title":"tgbn-trade","text":""},{"location":"gallery/tgbn-trade/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/tgbn-trade/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/tgbn-trade/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/tgbn-trade/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/uci/","title":"UCI","text":""},{"location":"gallery/uci/#uci","title":"UCI","text":""},{"location":"gallery/uci/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/uci/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/uci/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/uci/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/unvote/","title":"UN Vote","text":""},{"location":"gallery/unvote/#un-vote","title":"UN Vote","text":""},{"location":"gallery/unvote/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/unvote/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/unvote/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/unvote/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"gallery/uslegis/","title":"US Legis","text":""},{"location":"gallery/uslegis/#us-legis","title":"US Legis","text":""},{"location":"gallery/uslegis/#tea-plot","title":"TEA Plot","text":""},{"location":"gallery/uslegis/#tet-plot","title":"TET Plot","text":""},{"location":"gallery/uslegis/#average-degree-over-time","title":"Average degree over time","text":""},{"location":"gallery/uslegis/#node-and-edge-over-time","title":"Node and Edge over time","text":""},{"location":"io/io/","title":"IO","text":""},{"location":"io/io/#tgx.io.read.read_csv","title":"<code>read_csv(fname=None, header=False, index=False, t_col=2)</code>","text":"<p>Read temporal edgelist and store it in a dictionary. Parameters:     fname: directory of a dataset in .csv format or data object created from loading dgb/tgb datasets      header: whether first line of data file is header     index: whether the first column is row indices     t_col: column indext for timestamps (0 or 2)     ts_sorted: if data are sorted based on timestamp</p> <p>Returns:</p> Name Type Description <code>temp_edgelist</code> <code>dict</code> <p>A dictionary of edges and their frequency at each time interval</p> Source code in <code>tgx/io/read.py</code> <pre><code>def read_csv(fname: Union[str, object] = None, \n             header: bool = False,\n             index: bool = False,\n             t_col: int = 2,) -&gt; dict:\n\n    \"\"\"\n    Read temporal edgelist and store it in a dictionary.\n    Parameters:\n        fname: directory of a dataset in .csv format or data object created from loading dgb/tgb datasets \n        header: whether first line of data file is header\n        index: whether the first column is row indices\n        t_col: column indext for timestamps (0 or 2)\n        ts_sorted: if data are sorted based on timestamp\n\n    Returns:\n        temp_edgelist: A dictionary of edges and their frequency at each time interval\n    \"\"\"\n\n    start_col = 0\n    if index:\n        start_col = 1\n        t_col += 1\n\n    if t_col &lt; 2:\n        u_col = t_col + 1\n    else:\n        u_col = start_col\n    v_col = u_col + 1\n\n    cols_to_read = [u_col, v_col, t_col]\n\n    if (isinstance(fname, str)):\n        return _load_edgelist(fname, cols_to_read, header=header)\n    elif isinstance(fname, type) or isinstance(fname, object):\n        return _datasets_edgelist_loader(fname.data) \n    else:\n        raise TypeError(\"Invalid input\")\n</code></pre>"},{"location":"tutorials/data_loader/","title":"Load built-in and ported datasets from TGB","text":"In\u00a0[\u00a0]: Copied! <pre>import tgx\n</pre> import tgx In\u00a0[2]: Copied! <pre>data_name = \"tgbl-wiki\" \ndataset = tgx.tgb_data(data_name) #tgb datasets\nctdg = tgx.Graph(dataset)\n</pre> data_name = \"tgbl-wiki\"  dataset = tgx.tgb_data(data_name) #tgb datasets ctdg = tgx.Graph(dataset) <pre>raw file found, skipping download\nDataset directory is  /mnt/f/code/TGB/tgb/datasets/tgbl_wiki\nloading processed file\nNumber of loaded edges: 157474\nNumber of unique edges:18257\nAvailable timestamps:  152757\n</pre> In\u00a0[3]: Copied! <pre>dataset = tgx.builtin.uci()\nctdg = tgx.Graph(dataset)\n</pre> dataset = tgx.builtin.uci() ctdg = tgx.Graph(dataset) <pre>Number of loaded edges: 59835\nNumber of unique edges:20296\nAvailable timestamps:  58911\n</pre> <p>You can load your own custom dataset from <code>.csv</code> files and read it into a <code>tgx.Graph</code> object</p> <p>Let's start by loading a toy dataset into pandas and then visualize the rows</p> In\u00a0[4]: Copied! <pre>import pandas as pd\ntoy_fname = 'toy_data.csv'\ndf = pd.read_csv(toy_fname)\ndf\n</pre> import pandas as pd toy_fname = 'toy_data.csv' df = pd.read_csv(toy_fname) df Out[4]: time source destination 0 0 1 2 1 0 2 1 2 0 3 1 3 1 2 2 4 1 1 2 5 1 3 1 In\u00a0[5]: Copied! <pre>from tgx.io.read import read_csv\n# header indicates if there is a header row at the top\n# index whether the first column is row indices\n# t_col indicates which column corresponds to timestamps\nedgelist = read_csv(toy_fname, \n         header=True,\n         index=False,\n         t_col=0,)\ntgx.Graph(edgelist=edgelist)\n</pre> from tgx.io.read import read_csv # header indicates if there is a header row at the top # index whether the first column is row indices # t_col indicates which column corresponds to timestamps edgelist = read_csv(toy_fname,           header=True,          index=False,          t_col=0,) tgx.Graph(edgelist=edgelist) <pre>Number of loaded edges: 5\nNumber of unique edges: 4\nAvailable timestamps:  2\n</pre> Out[5]: <pre>&lt;tgx.classes.graph.Graph at 0x7fde4755aca0&gt;</pre> In\u00a0[6]: Copied! <pre>from tgx.utils.graph_utils import subsampling\n\nsub_edges = subsampling(ctdg, selection_strategy=\"random\", N=1000) #N is # of nodes to be sampled \nsubgraph = tgx.Graph(edgelist=sub_edges)\n</pre> from tgx.utils.graph_utils import subsampling  sub_edges = subsampling(ctdg, selection_strategy=\"random\", N=1000) #N is # of nodes to be sampled  subgraph = tgx.Graph(edgelist=sub_edges) <pre>Generate graph subsample...\n</pre>"},{"location":"tutorials/data_loader/#load-built-in-and-ported-datasets-from-tgb","title":"Load built-in and ported datasets from TGB\u00b6","text":"<p>This tutorial shows you how to load built-in datasets</p>"},{"location":"tutorials/data_loader/#access-tgb-datasets","title":"Access TGB datasets\u00b6","text":"<p>In order to load TGB datasets you should first install the TGB package:</p> <p><code>pip install py-tgb</code></p> <p>Then write name of the dataset in the parantheses:</p> <p><code>tgx.data.tgb(\"name\")</code></p> <p>The dataset names are as follow</p> <p><code>tgbl-wiki</code>, <code>tgbl-review</code>, <code>tgbl-coin</code>, <code>tgbl-comment</code>, <code>tgbl-flight</code></p> <p><code>tgbn-trade</code>, <code>tgbn-genre</code>, <code>tgbn-reddit</code></p>"},{"location":"tutorials/data_loader/#access-other-datasets","title":"Access other datasets\u00b6","text":"<p>To load built-in TGX datasets (from Poursafaei et al. 2022). You can write the name of the dataset instead of <code>datasest_name</code>:</p> <p><code>tgx.data.dataset_name</code></p> <p>The dataset names are as:</p> <p><code>mooc</code>, <code>uci</code>, <code>uslegis</code>, <code>unvote</code>, <code>untrade</code>, <code>flight</code>, <code>wikipedia</code>, <code>reddit</code>, <code>lastfm</code>, <code>contact</code>, <code>canparl</code>, <code>socialevo</code>, <code>enron</code></p>"},{"location":"tutorials/data_loader/#custom-datasets","title":"Custom Datasets\u00b6","text":""},{"location":"tutorials/data_loader/#subsampling-graphs","title":"Subsampling graphs\u00b6","text":"<p>To perform subsmpling graphs you should follow these steps:</p> <ol> <li><p>descritize the data</p> </li> <li><p>create a graph object of data (G)</p> </li> <li><p>subsample the graph by <code>tgx.utils.graph_utils.subsampling</code></p> </li> <li><p>create a new graph from the subsampled subgraph</p> </li> </ol>"},{"location":"tutorials/data_viz_stats/","title":"Dataset Visualization and Statistics","text":"<p>This tutorial shows you how to use TGX for visualizations and obtaining dataset statistics.</p> <p>For comprehensive API references, visit TGX website.</p> In\u00a0[2]: Copied! <pre>import tgx\nfrom tgx.utils.plotting_utils import plot_for_snapshots\n</pre> import tgx from tgx.utils.plotting_utils import plot_for_snapshots Tip: For all suported TGB datasets, see tgx/data/tgb.py and data loading tutorial In\u00a0[3]: Copied! <pre>data_name = \"tgbl-wiki\"\ndataset = tgx.tgb_data(data_name)\n</pre> data_name = \"tgbl-wiki\" dataset = tgx.tgb_data(data_name)  <pre>Dataset tgbl-wiki version 2 not found.\nPlease download the latest version of the dataset.\nDownload started, this might take a while . . . \nDataset title: tgbl-wiki\nDownload completed \nDataset directory is  /home/fpour/projects/def-rrabba/fpour/proj/TGX/ENV/lib/python3.11/site-packages/tgb/datasets/tgbl_wiki\nfile not processed, generating processed file\n</pre> Tip: For all built-in datasets, see tgx/data/builtin.py and data loading tutorial In\u00a0[4]: Copied! <pre>dataset = tgx.builtin.uci()\n</pre> dataset = tgx.builtin.uci()  <pre>Data missing, download recommended!\n./data\nhttps://zenodo.org/record/7213796/files/uci.zip\nDownloading uci dataset . . .\nDownload completed\n</pre> In\u00a0[5]: Copied! <pre>ctdg = tgx.Graph(dataset) # retrieve the continuous time dynamic graph\ntime_scale = \"weekly\" #\"minutely\", \"hourly\", \"daily\", \"monthly\", \"yearly\", \"biyearly\"\ndtdg, ts_list = ctdg.discretize(time_scale=time_scale, store_unix=True)\n</pre> ctdg = tgx.Graph(dataset) # retrieve the continuous time dynamic graph time_scale = \"weekly\" #\"minutely\", \"hourly\", \"daily\", \"monthly\", \"yearly\", \"biyearly\" dtdg, ts_list = ctdg.discretize(time_scale=time_scale, store_unix=True) <pre>Number of loaded edges: 59835\nNumber of unique edges:20296\nAvailable timestamps:  58911\nDiscretizing data to 28 timestamps...\n</pre> Tip: The discretization function returns the discretized TG as its first argument (dtdg) and the remapped unix timestamps as its second argument (ts_list). The dtdg has integer timestamps (snapshot ids) thus ts_list keep tracks of the unix timestamps of all edges in the coarsened time granularity.    <p>TGX provides a suite of visualization tools for better analyzing the dynamics of temporal graphs.</p> <p>Below is a list of visualization approaches offered by TGX.</p> Important: A discretized graph should be provided as input.  Function Description <code>tgx.degree_over_time</code> Plot the average node degree over time <code>tgx.nodes_over_time</code> Plot the number of active nodes per snapshot <code>tgx.edges_over_time</code> Plot the number of edges per snapshot <code>tgx.nodes_and_edges_over_time</code> Plot the number of active nodes and edges in the same figure <code>tgx.connected_components_per_ts</code> Plot the number of connected components per timestamp. <code>tgx.degree_density</code> Plot the density map of node degrees per time window <code>tgx.TEA</code>-Plot) Plot Temporal Edge Appearance (TEA) (from Poursafaei et al. 2022) <code>tgx.TET</code>-Plot) Plot Temporal Edge Traffic (TET) from (Poursafaei et al. 2022) <p>For each visualization tool, you can specify the output path with <code>filepath</code>, otherwise the output is saved in the current directory.</p> Example: <code> tgx.degree_over_time(dtdg, network_name=dataset.name, filepath=filepath) </code> <p>In what follows, we cover some of the visualizations offered by TGX.</p> In\u00a0[6]: Copied! <pre>tgx.degree_over_time(dtdg, network_name=dataset.name)\n</pre> tgx.degree_over_time(dtdg, network_name=dataset.name) In\u00a0[7]: Copied! <pre>tgx.nodes_over_time(dtdg, network_name=dataset.name)\n</pre> tgx.nodes_over_time(dtdg, network_name=dataset.name) In\u00a0[8]: Copied! <pre>tgx.edges_over_time(dtdg, network_name=dataset.name)\n</pre> tgx.edges_over_time(dtdg, network_name=dataset.name) In\u00a0[10]: Copied! <pre>tgx.nodes_and_edges_over_time(dtdg, network_name=dataset.name)\n</pre> tgx.nodes_and_edges_over_time(dtdg, network_name=dataset.name) <pre>Plotting number of nodes and edges per timestamp.\n</pre> In\u00a0[11]: Copied! <pre>tgx.connected_components_per_ts(dtdg, network_name=dataset.name)\n</pre> tgx.connected_components_per_ts(dtdg, network_name=dataset.name) In\u00a0[12]: Copied! <pre>tgx.degree_density(dtdg, k=3, network_name=dataset.name)\n</pre> tgx.degree_density(dtdg, k=3, network_name=dataset.name) In\u00a0[14]: Copied! <pre>tgx.TEA(dtdg, \n        network_name=dataset.name)\n</pre> tgx.TEA(dtdg,          network_name=dataset.name) <pre>plot saved as ./uci_TEA.pdf\n</pre> In\u00a0[15]: Copied! <pre>tgx.TET(dtdg, \n        network_name=dataset.name, \n        figsize = (9, 5),\n        axis_title_font_size = 24,\n        ticks_font_size = 24)\n</pre> tgx.TET(dtdg,          network_name=dataset.name,          figsize = (9, 5),         axis_title_font_size = 24,         ticks_font_size = 24) <pre>Info: Number of distinct edges (from index-edge map): 20296\n</pre> <pre>29it [00:00, 3438.15it/s]\n</pre> <pre>Info: edge-presence-matrix shape: (29, 20296)\nFirst level processing: \nDetecting edges present in train &amp; test sets\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24/24 [00:01&lt;00:00, 20.33it/s]\n</pre> <pre>Detecting transductive edges (seen in train, repeating in test)\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 23.35it/s]\n</pre> <pre>Second level processing:\nDetecting edges 1) Only in train set, 2) only in test (inductive)\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 29/29 [00:01&lt;00:00, 24.76it/s]\n</pre> <pre>Info: edge-presence-matrix shape: (29, 20296)\nInfo: plotting edge presence heatmap for . ...\n</pre> <pre>Info: plotting done!\n</pre> Function Description Returns <code>tgx.get_reoccurrence</code> Calculate the recurrence index <code>float</code> <code>tgx.get_surprise</code> Calculate the surprise index <code>float</code> <code>tgx.get_novelty</code> Calculate the novelty index <code>float</code> <code>tgx.get_avg_node_activity</code> Calculate the average node activity <code>float</code> <code>tgx.size_connected_components</code> Calculate the sizes of connected components <code>List[List[float]]</code> <code>tgx.get_avg_node_engagement</code> Calculate the average node engagement <code>List[float]</code> <p>Since some the measures require distinct test split, we should first set the <code>test_ratio</code>. Please note that temporal graph data is generally split in a chronological manner.</p> <p>You can use <code>plot_for_snapshots</code> for visualizing the statistics reports.</p> In\u00a0[17]: Copied! <pre>test_ratio = 0.15\n\n# compute reocurrence\ntgx.get_reoccurrence(ctdg, test_ratio=test_ratio)\n\n# compute surprise\ntgx.get_surprise(ctdg, test_ratio=test_ratio)\n\n# compute novelty\ntgx.get_novelty(dtdg)\n\n# compute node activity\ntgx.get_avg_node_activity(dtdg)\n</pre> test_ratio = 0.15  # compute reocurrence tgx.get_reoccurrence(ctdg, test_ratio=test_ratio)  # compute surprise tgx.get_surprise(ctdg, test_ratio=test_ratio)  # compute novelty tgx.get_novelty(dtdg)  # compute node activity tgx.get_avg_node_activity(dtdg) <pre>INFO: Reoccurrence: 0.03712061378765655\nINFO: Surprise: 0.7961586121437423\nINFO: Novelty: 0.6590964516995399\nINFO: Node activity ratio: 0.16558624321330645\n</pre> Out[17]: <pre>0.16558624321330645</pre> In\u00a0[18]: Copied! <pre>component_sizes = tgx.size_connected_components(dtdg)\nlargest_component_sizes = [max(inner_list) if inner_list else 0 for inner_list in component_sizes]\nfilename = f\"{dataset.name}_largest_connected_component_size\"\nplot_for_snapshots(largest_component_sizes, y_title=\"Size of Largest Connected Component\", filename=\"./\"+filename)\n</pre> component_sizes = tgx.size_connected_components(dtdg) largest_component_sizes = [max(inner_list) if inner_list else 0 for inner_list in component_sizes] filename = f\"{dataset.name}_largest_connected_component_size\" plot_for_snapshots(largest_component_sizes, y_title=\"Size of Largest Connected Component\", filename=\"./\"+filename) In\u00a0[19]: Copied! <pre>engagements = tgx.get_avg_node_engagement(dtdg)\nfilename = f\"{dataset.name}_average_node_engagement\"\nplot_for_snapshots(engagements, y_title=\"Average Engagement\", filename=\"./\"+filename)\n</pre> engagements = tgx.get_avg_node_engagement(dtdg) filename = f\"{dataset.name}_average_node_engagement\" plot_for_snapshots(engagements, y_title=\"Average Engagement\", filename=\"./\"+filename)"},{"location":"tutorials/data_viz_stats/#dataset-visualization-and-statistics","title":"Dataset Visualization and Statistics\u00b6","text":""},{"location":"tutorials/data_viz_stats/#load-tgb-dataset","title":"Load TGB Dataset\u00b6","text":"<p>For the examples used in this tutorials, first, load the TGB datasets in TGX from Temporal Graph Benchmark for Machine Learning on Temporal Graphs (NeurIPS 2023 Datasets and Benchmarks Track).</p>"},{"location":"tutorials/data_viz_stats/#load-built-in-dataset","title":"Load Built-in Dataset\u00b6","text":"<p>Load the built-in datasets in TGX that come from Towards Better Evaluation for Dynamic Link Prediction (NeurIPS 2022 Datasets and Benchmarks Track).</p>"},{"location":"tutorials/data_viz_stats/#graph-discretization-for-visualization","title":"Graph Discretization for Visualization\u00b6","text":"<p>We can discretize a temporal graph into snapshots (i.e., equally spaced durations) for visualization purposes.</p>"},{"location":"tutorials/data_viz_stats/#tgx-features","title":"TGX Features\u00b6","text":""},{"location":"tutorials/data_viz_stats/#average-node-degree-over-time","title":"Average Node Degree Over Time\u00b6","text":"<p>The goal is to plot the average node degree of snapshot.</p> <p>In this plot, the x-axis is the snapshot index (or timestamps), while the y-axis is the average node degree.</p>"},{"location":"tutorials/data_viz_stats/#number-of-nodes-over-time","title":"Number of Nodes Over Time\u00b6","text":"<p>The goal is to plot the number of active nodes per snapshot.</p> <p>In this plot, x-axis is the snapshot index (or timestamps), while the y-axis denotes the number of active nodes.</p>"},{"location":"tutorials/data_viz_stats/#number-of-edges-over-time","title":"Number of Edges Over Time\u00b6","text":"<p>The goal is to plot the number of edges per snapshot.</p> <p>The x-axis is the snapshot index (or timestamps), while the y-axis denotes the number of edges.</p>"},{"location":"tutorials/data_viz_stats/#number-of-nodes-and-edges-over-time","title":"Number of Nodes and Edges Over Time\u00b6","text":"<p>The goal is to plot the number of active nodes and edges per snapshot in the same figure.</p> <p>The x-axis is the snapshot index (or timestamps), while the y-axis denotes the active number of nodes / edges.</p>"},{"location":"tutorials/data_viz_stats/#number-of-connected-components","title":"Number of Connected Components\u00b6","text":"<p>The goal is to plot number of connected components per snapshot.</p> <p>The x-axis is the snapshot index (or timestamps), while the y-axis denotes the number of connected components.</p>"},{"location":"tutorials/data_viz_stats/#degree-density","title":"Degree Density\u00b6","text":"<p>The goal is to plot the heatmap of node degrees per snapshot.</p> <p>The x-axis is the snapshot index (or timestamps), while the y-axis denotes the node degree.</p>"},{"location":"tutorials/data_viz_stats/#temporal-edge-appearance-tea-plot","title":"Temporal Edge Appearance (TEA) Plot\u00b6","text":"<p>A TEA plot illustrates the portion of repeated edges versus newly observed edges for each timestamp in a dynamic graph.</p> <p>This plot is proposed in Poursafaei et al. 2022.</p>"},{"location":"tutorials/data_viz_stats/#temporal-edge-traffic-tet-plot","title":"Temporal Edge Traffic (TET) Plot\u00b6","text":"<p>A TET plot visualizes the reocurrence pattern of edges in different dynamic networks over time</p> <p>This plot is proposed in Poursafaei et al. 2022.</p>"},{"location":"tutorials/data_viz_stats/#temporal-graph-statistics","title":"Temporal Graph Statistics\u00b6","text":"<p>TGX provides APIs to compute the statistics of temporal graphs.</p> <p>Here, we cover some the functionalities for obtaining temporal graph statistics provided by TGX.</p>"},{"location":"tutorials/data_viz_stats/#size-of-connected-components","title":"Size of Connected Components\u00b6","text":"<p>You can also visualize some statistics such as how the size of the largest component changes over time.</p>"},{"location":"tutorials/data_viz_stats/#average-node-engagement","title":"Average Node Engagement\u00b6","text":"<p>The goal is to calculate the average node engagement over time. Node engagement represents the average number of distinct nodes that establish at least one new connection during a timestamp.</p>"},{"location":"utils/graph_stats/","title":"Graph stats","text":""},{"location":"utils/graph_stats/#graph-stats","title":"Graph Stats","text":""},{"location":"utils/graph_stats/#tgx.utils.stat.connected_components_per_ts","title":"<code>connected_components_per_ts(graph, network_name=None, plot_path='./')</code>","text":"<p>Plot number of connected components per timestamp Parameters:     graph: a list containing graph snapshots     network_name: name of the graph to be used in the output file name     plot_path: path to save the output figure</p> Source code in <code>tgx/utils/stat.py</code> <pre><code>def connected_components_per_ts(graph: tuple,  \n                 network_name: str = None,\n                 plot_path: str = \"./\") -&gt; None:\n    r\"\"\"\n    Plot number of connected components per timestamp\n    Parameters:\n        graph: a list containing graph snapshots\n        network_name: name of the graph to be used in the output file name\n        plot_path: path to save the output figure\n    \"\"\"\n    num_components = []\n    for t in range(len(graph.data)):\n        edgelist_t = graph.data[t]\n        nodes_t = graph.edgelist_node_list(edgelist_t)\n        parent = {node: node for node in nodes_t} \n\n        for edge in edgelist_t:\n            (u, v) = edge\n            _merge(u, v, parent)\n\n        num = 0\n        for u in nodes_t:\n            if parent[u] == u:\n                num += 1       \n        num_components.append(num)  \n\n    if network_name is not None:\n        filename = f\"{network_name}_connected_components_per_ts\"\n    else:\n        filename = \"_connected_components_per_ts\"\n\n    plot_for_snapshots(num_components, y_title=\"Number of connected components\", filename=plot_path+filename)\n    return \n</code></pre>"},{"location":"utils/graph_stats/#tgx.utils.stat.degree_density","title":"<code>degree_density(graph, k=10, network_name=None, plot_path='./')</code>","text":"<p>Plot density map of node degrees per time window Parameters:     graph_edgelist: Dictionary containing graph data     k: number of time windows     network_name: name of the graph to be used in the output file name     plot_path: path to save the output figure</p> Source code in <code>tgx/utils/stat.py</code> <pre><code>def degree_density(graph: tuple, \n                   k: int = 10, \n                   network_name: str = None, \n                   plot_path: str = \"./\") -&gt; None:\n    r\"\"\"\n    Plot density map of node degrees per time window\n    Parameters:\n        graph_edgelist: Dictionary containing graph data\n        k: number of time windows\n        network_name: name of the graph to be used in the output file name\n        plot_path: path to save the output figure\n    \"\"\"\n    graph_edgelist = graph.data\n    degrees_by_k_list = []\n    temp = []\n    temp_idx = 0\n    unique_ts = list(graph_edgelist.keys())\n\n    for ts in unique_ts:\n        e_at_this_ts = graph_edgelist[ts]\n        G = nx.MultiGraph()\n\n        for e in e_at_this_ts:\n            G.add_edge(e[0], e[1])\n\n        nodes = G.nodes()\n        degrees = [G.degree[n] for n in nodes]\n\n        if temp_idx&lt;k:\n            temp.extend(degrees)\n            temp_idx += 1\n        else: \n            degrees_by_k_list.append(temp)\n            temp = degrees\n            temp_idx = 1\n\n    if temp:\n        degrees_by_k_list.append(temp)\n\n    if network_name is not None:\n        filename = f\"{network_name}_degree_density\"\n    else:\n        filename = \"_degree_density\"\n\n    plot_density_map(degrees_by_k_list, y_title=\"Node Degree\", filename = plot_path + filename)\n    return \n</code></pre>"},{"location":"utils/graph_stats/#tgx.utils.stat.degree_over_time","title":"<code>degree_over_time(graph, network_name, filepath='./')</code>","text":"<p>Plot average degree per timestamp. Parameters:  graph: Graph object created by tgx.Graph containing edgelist  network_name: name of the graph to be used in the output file name  filepath: path to save the output figure</p> Source code in <code>tgx/utils/stat.py</code> <pre><code>def degree_over_time(graph: object,  \n                    network_name: str,\n                    filepath: str = \"./\") -&gt; None:\n    r'''\n    Plot average degree per timestamp.\n    Parameters:\n     graph: Graph object created by tgx.Graph containing edgelist\n     network_name: name of the graph to be used in the output file name\n     filepath: path to save the output figure\n    '''\n    ave_degree = _calculate_average_degree_per_ts(graph)\n\n    if network_name is not None:\n        filename = f\"{network_name}_ave_degree_per_ts\"\n    else:\n        filename = \"ave_degree_per_ts\"\n    plot_for_snapshots(ave_degree, y_title= \"Average degree\", filename=filepath+filename)    \n    return \n</code></pre>"},{"location":"utils/graph_stats/#tgx.utils.stat.edges_over_time","title":"<code>edges_over_time(graph, network_name=None, filepath='./')</code>","text":"<p>Plot number of edges per timestamp. Parameters:  graph: Graph object created by tgx.Graph containing edgelist  network_name: name of the graph to be used in the output file name  filepath: path to save the output figure</p> Source code in <code>tgx/utils/stat.py</code> <pre><code>def edges_over_time(graph: object, \n                 network_name: str = None,\n                 filepath: str = \"./\") -&gt; None:\n    r'''\n    Plot number of edges per timestamp.\n    Parameters:\n     graph: Graph object created by tgx.Graph containing edgelist\n     network_name: name of the graph to be used in the output file name\n     filepath: path to save the output figure\n    '''\n    active_edges = _calculate_edge_per_ts(graph)\n    if network_name is not None:\n        filename = f\"{network_name}_edges_per_ts\"\n    else:\n        filename = \"_edges_per_ts\"\n    plot_for_snapshots(active_edges, y_title=\"Number of edges\", filename=filepath+filename)\n    return \n</code></pre>"},{"location":"utils/graph_stats/#tgx.utils.stat.get_avg_degree","title":"<code>get_avg_degree(graph)</code>","text":"<p>Calculate average degree over the timestamps Parameters:  graph: Graph object created by tgx.Graph containing edgelist</p> Source code in <code>tgx/utils/stat.py</code> <pre><code>def get_avg_degree(graph: object) -&gt; float:\n    r\"\"\"\n    Calculate average degree over the timestamps\n    Parameters:\n     graph: Graph object created by tgx.Graph containing edgelist\n    \"\"\"\n    graph_edgelist = graph.data\n    degree_avg_at_ts_list = []\n    unique_ts = list(graph_edgelist.keys())\n    for ts in unique_ts:\n        e_at_this_ts = graph_edgelist[ts]\n        G = nx.MultiGraph()\n        for e, repeat in e_at_this_ts.items():\n            G.add_edge(e[0], e[1], weight=repeat)\n        nodes = G.nodes()\n        degrees = [G.degree[n] for n in nodes]\n        degree_avg_at_ts_list.append(np.mean(degrees))\n\n    print(f\"INFO: avg_degree: {np.mean(degree_avg_at_ts_list)}\")\n    return np.mean(degree_avg_at_ts_list)\n</code></pre>"},{"location":"utils/graph_stats/#tgx.utils.stat.get_avg_e_per_ts","title":"<code>get_avg_e_per_ts(graph_edgelist)</code>","text":"<p>Calculate the average number of edges per timestamp</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <p>Graph object created by tgx.Graph containing edgelist</p> required Source code in <code>tgx/utils/stat.py</code> <pre><code>def get_avg_e_per_ts(graph_edgelist: dict) -&gt; float:\n    r\"\"\"\n    Calculate the average number of edges per timestamp\n\n    Parameters:\n     graph: Graph object created by tgx.Graph containing edgelist\n    \"\"\"\n    sum_num_e_per_ts = 0\n    unique_ts = list(graph_edgelist.keys())\n    for ts in unique_ts:\n        num_e_at_this_ts = 0\n        edge_at_this_ts = graph_edgelist[ts]\n        for e, repeat in edge_at_this_ts.items():\n            num_e_at_this_ts += repeat\n        sum_num_e_per_ts += num_e_at_this_ts\n    avg_num_e_per_ts = (sum_num_e_per_ts * 1.0) / len(unique_ts)\n\n    print(f\"INFO: avg_num_e_per_ts: {avg_num_e_per_ts}\")\n    return avg_num_e_per_ts\n</code></pre>"},{"location":"utils/graph_stats/#tgx.utils.stat.get_avg_node_activity","title":"<code>get_avg_node_activity(graph)</code>","text":"<p>Calculate the average node activity,     the proportion of time steps a node is present Parameters:     graph: Graph object created by tgx.Graph containing edgelist</p> Source code in <code>tgx/utils/stat.py</code> <pre><code>def get_avg_node_activity(graph: object) -&gt; float:\n    r\"\"\"\n    Calculate the average node activity,\n        the proportion of time steps a node is present\n    Parameters:\n        graph: Graph object created by tgx.Graph containing edgelist\n    \"\"\"\n    graph_edgelist = graph.data\n    num_unique_ts = len(graph_edgelist)\n    node_ts = {}\n    for ts, e_list in graph_edgelist.items():\n        for e in e_list:\n            # source\n            if e[0] not in node_ts:\n                node_ts[e[0]] = {ts: True}\n            else:\n                if ts not in node_ts[e[0]]:\n                    node_ts[e[0]][ts] = True\n\n            # destination\n            if e[1] not in node_ts:\n                node_ts[e[1]] = {ts: True}\n            else:\n                if ts not in node_ts[e[1]]:\n                    node_ts[e[1]][ts] = True\n\n    node_activity_ratio = []\n    for n, ts_list in node_ts.items():\n        node_activity_ratio.append(float(len(ts_list) * 1.0 / num_unique_ts))\n\n    avg_node_activity = float(np.sum(node_activity_ratio) * 1.0 / len(node_activity_ratio))\n    print(f\"INFO: Node activity ratio: {avg_node_activity}\")\n    return avg_node_activity\n</code></pre>"},{"location":"utils/graph_stats/#tgx.utils.stat.get_avg_node_engagement","title":"<code>get_avg_node_engagement(graph)</code>","text":"<p>Calculate the average node engagement per timestamp,     the average number of distinct nodes that establish     at least one new connection. Parameters:     graph_edgelist: Dictionary containing graph data</p> Source code in <code>tgx/utils/stat.py</code> <pre><code>def get_avg_node_engagement(graph: tuple) -&gt; List[int]: \n    r\"\"\"\n    Calculate the average node engagement per timestamp,\n        the average number of distinct nodes that establish\n        at least one new connection.\n    Parameters:\n        graph_edgelist: Dictionary containing graph data\n    \"\"\"\n    engaging_nodes = []\n    previous_edges = set()\n\n    for ts in range(len(graph.data)):\n        edgelist_t = graph.data[ts]\n        new_nodes = set()\n\n        for edge in edgelist_t:\n            (u, v) = edge\n            if frozenset({u, v}) not in previous_edges:\n                if u not in new_nodes:\n                    new_nodes.add(u)\n                if v not in new_nodes:\n                    new_nodes.add(v)   \n\n        engaging_nodes.append(len(new_nodes))\n        previous_edges = {frozenset({u, v}) for (u, v) in edgelist_t}        # Update the set of previous edges for next timestamp\n\n    return engaging_nodes\n</code></pre>"},{"location":"utils/graph_stats/#tgx.utils.stat.get_novelty","title":"<code>get_novelty(graph)</code>","text":"<p>Calculate the novelty index Parameters:     graph: Graph object created by tgx.Graph containing edgelist</p> Source code in <code>tgx/utils/stat.py</code> <pre><code>def get_novelty(graph : object) -&gt; float:\n    r\"\"\"\n    Calculate the novelty index\n    Parameters:\n        graph: Graph object created by tgx.Graph containing edgelist\n    \"\"\"\n    graph_edgelist = graph.data\n    unique_ts = np.sort(list(graph_edgelist.keys()))\n    novelty_ts = []\n    for ts_idx, ts in enumerate(unique_ts):\n        e_set_this_ts = set(list(graph_edgelist[ts]))\n        e_set_seen = []\n        for idx in range(0, ts_idx):\n            e_set_seen.append(list(graph_edgelist[unique_ts[idx]]))\n        e_set_seen = set(item for sublist in e_set_seen for item in sublist)\n        novelty_ts.append(float(len(e_set_this_ts - e_set_seen) * 1.0 / len(e_set_this_ts)))\n\n    novelty = float(np.sum(novelty_ts) * 1.0 / len(unique_ts))\n    print(f\"INFO: Novelty: {novelty}\")\n    return novelty\n</code></pre>"},{"location":"utils/graph_stats/#tgx.utils.stat.get_num_timestamps","title":"<code>get_num_timestamps(graph_edgelist)</code>","text":"<p>Calculate the number of timestamps Parameters:  graph: Graph object created by tgx.Graph containing edgelist</p> Source code in <code>tgx/utils/stat.py</code> <pre><code>def get_num_timestamps(graph_edgelist:dict) -&gt; int:\n    r\"\"\"\n    Calculate the number of timestamps\n    Parameters:\n     graph: Graph object created by tgx.Graph containing edgelist\n    \"\"\"\n    print(f\"INFO: Number of timestamps: {len(graph_edgelist)}\")\n    return len(graph_edgelist)\n</code></pre>"},{"location":"utils/graph_stats/#tgx.utils.stat.get_num_unique_edges","title":"<code>get_num_unique_edges(graph)</code>","text":"<p>Calculate the number of unique edges Parameters:  graph: Graph object created by tgx.Graph containing edgelist</p> Source code in <code>tgx/utils/stat.py</code> <pre><code>def get_num_unique_edges(graph: object) -&gt; int:\n    r\"\"\"\n    Calculate the number of unique edges\n    Parameters:\n     graph: Graph object created by tgx.Graph containing edgelist\n    \"\"\"\n    graph_edgelist = graph.data\n    unique_edges = {}\n    for ts, e_list in graph_edgelist.items():\n        for e in e_list:\n            if e not in unique_edges:\n                unique_edges[e] = 1\n    print(f\"INFO: Number of unique edges: {len(unique_edges)}\")\n    return len(unique_edges)\n</code></pre>"},{"location":"utils/graph_stats/#tgx.utils.stat.get_reoccurrence","title":"<code>get_reoccurrence(graph, test_ratio=0.15)</code>","text":"<p>Calculate the recurrence index Parameters:     graph: Graph object created by tgx.Graph containing edgelist     test_ratio: The ratio to split the data chronologically</p> Source code in <code>tgx/utils/stat.py</code> <pre><code>def get_reoccurrence(graph:object, test_ratio: float=0.15) -&gt; float:\n    r\"\"\"\n    Calculate the recurrence index\n    Parameters:\n        graph: Graph object created by tgx.Graph containing edgelist\n        test_ratio: The ratio to split the data chronologically\n    \"\"\"\n    graph_edgelist = graph.data\n    train_val_e_set, test_e_set = _split_data_chronological(graph_edgelist, test_ratio)\n    train_val_size = len(train_val_e_set)\n    # intersect = 0\n    # total_train_freq = 0\n    # for e, freq in train_val_e_set.items():\n    #     if freq &gt; 1:\n    #         print(e)\n    #     total_train_freq += freq\n    #     if e in test_e_set:\n    #         intersect += freq\n\n    # print(total_train_freq, intersect)\n    # reoccurrence = float(intersect * 1.0 / total_train_freq)\n    intersect = 0\n    for e in test_e_set:\n        if e in train_val_e_set:\n            intersect += 1\n    reoccurrence = float(intersect * 1.0 / train_val_size)\n    print(f\"INFO: Reoccurrence: {reoccurrence}\")\n    return reoccurrence\n</code></pre>"},{"location":"utils/graph_stats/#tgx.utils.stat.get_surprise","title":"<code>get_surprise(graph, test_ratio=0.15)</code>","text":"<p>Calculate the surprise index Parameters:     graph: Graph object created by tgx.Graph containing edgelist     test_ratio: The ratio to split the data chronologically</p> Source code in <code>tgx/utils/stat.py</code> <pre><code>def get_surprise(graph, test_ratio: float = 0.15) -&gt; float:\n    r\"\"\"\n    Calculate the surprise index\n    Parameters:\n        graph: Graph object created by tgx.Graph containing edgelist\n        test_ratio: The ratio to split the data chronologically\n    \"\"\"\n    graph_edgelist = graph.data\n    train_val_e_set, test_e_set = _split_data_chronological(graph_edgelist, test_ratio)\n    test_size = len(test_e_set)\n\n    difference = 0\n    # total_test_freq = 0\n    # for e, freq in test_e_set.items():\n    #     total_test_freq += freq\n    #     if e not in train_val_e_set:\n    #         difference += freq\n    # surprise = float(difference * 1.0 / total_test_freq)\n\n    for e in test_e_set:\n        if e not in train_val_e_set:\n            difference += 1\n    surprise = float(difference * 1.0 / test_size)\n    print(f\"INFO: Surprise: {surprise}\")\n    return surprise\n</code></pre>"},{"location":"utils/graph_stats/#tgx.utils.stat.nodes_and_edges_over_time","title":"<code>nodes_and_edges_over_time(graph, network_name, filepath='./')</code>","text":"<p>Plot number of nodes per timestamp and number of edges per timestamp in one fiugre. Parameters:  graph: Graph object created by tgx.Graph containing edgelist  network_name: name of the graph to be used in the output file name  filepath: path to save the output figure</p> Source code in <code>tgx/utils/stat.py</code> <pre><code>def nodes_and_edges_over_time(graph: object, \n                           network_name: str ,\n                           filepath: str = \"./\"):\n    r\"\"\"\n    Plot number of nodes per timestamp and number of edges per timestamp in one fiugre.\n    Parameters:\n     graph: Graph object created by tgx.Graph containing edgelist\n     network_name: name of the graph to be used in the output file name\n     filepath: path to save the output figure\n    \"\"\"\n    print(\"Plotting number of nodes and edges per timestamp.\")\n    edges = _calculate_edge_per_ts(graph)\n    nodes = _calculate_node_per_ts(graph)\n    ts = list(range(0, len(graph.data)))\n    if network_name is not None:\n        filename = f\"{network_name}_node_and_edges_per_ts\"\n    else:\n        filename = \"node_and_edges_per_ts\"\n    return plot_nodes_edges_per_ts(edges, nodes, ts, filename=filepath+filename)\n</code></pre>"},{"location":"utils/graph_stats/#tgx.utils.stat.nodes_over_time","title":"<code>nodes_over_time(graph, network_name, filepath='./')</code>","text":"<p>Plot number of active nodes per timestamp. Parameters:  graph: Graph object created by tgx.Graph containing edgelist  network_name: name of the graph to be used in the output file name  filepath: path to save the output figure</p> Source code in <code>tgx/utils/stat.py</code> <pre><code>def nodes_over_time(graph: object,  \n                 network_name: str,\n                 filepath: str = \"./\") -&gt; None:\n\n    r'''\n    Plot number of active nodes per timestamp.\n    Parameters:\n     graph: Graph object created by tgx.Graph containing edgelist\n     network_name: name of the graph to be used in the output file name\n     filepath: path to save the output figure\n    '''\n    active_nodes = _calculate_node_per_ts(graph)\n    if network_name is not None:\n        filename = f\"{network_name}_nodes_per_ts\"\n    else:\n        filename = \"nodes_per_ts\"\n    plot_for_snapshots(active_nodes, y_title=\"Number of nodes\", filename=filepath+filename)\n    return \n</code></pre>"},{"location":"utils/graph_stats/#tgx.utils.stat.size_connected_components","title":"<code>size_connected_components(graph)</code>","text":"<p>Calculate the sizes of connected components per timestamp Returns:     list[list]: A list containing lists of sizes of connected components for each timestamp.</p> Source code in <code>tgx/utils/stat.py</code> <pre><code>def size_connected_components(graph: tuple) -&gt; List[List]: \n    r\"\"\"\n    Calculate the sizes of connected components per timestamp\n    Returns:\n        list[list]: A list containing lists of sizes of connected components for each timestamp.\n    \"\"\"\n    component_sizes = []\n    for t in range(len(graph.data)):\n        edgelist_t = graph.data[t]\n        nodes_t = graph.edgelist_node_list(edgelist_t)\n        parent = {node: node for node in nodes_t} \n\n        for edge in edgelist_t:\n            (u, v) = edge\n            _merge(u, v, parent)\n\n        component_sizes_t = {}\n        for u in nodes_t:\n            root = _find(u, parent)\n            if root not in component_sizes_t:\n                component_sizes_t[root] = 0  \n            component_sizes_t[root] += 1  \n\n        component_sizes_t_list = list(component_sizes_t.values())\n        component_sizes.append(component_sizes_t_list)\n\n    return component_sizes\n</code></pre>"},{"location":"utils/graph_utils/","title":"Graph Utils","text":""},{"location":"utils/graph_utils/#graph-utils","title":"Graph Utils","text":""},{"location":"utils/graph_utils/#tgx.utils.graph_utils.discretize_edges","title":"<code>discretize_edges(edgelist, time_scale, store_unix=False, freq_weight=False)</code>","text":"<p>util function for discretizing edgelist, expected timestamp on edges are unixtimestamp this func supports discretization of edge timestamp  1. by providing the number of intervals (int), it will equally divide the data into that number of intervals. Note that the last bin can have less duration than others. 2. by providing a time granularity (str), it will divide the data into intervals based on the given granularity, i.e. \"hourly\", \"daily\", \"weekly\", \"monthly\", \"yearly\", the starting time of the dataset is consider the start of the first interval Parameters:     edgelist: dict, dictionary of edges     time_scale: int or str, time interval to discretize the graph     store_unix: bool, whether to return the converted timestamps in unix format     freq_weight: bool, whether to weight the edges based on their frequency Returns:     output list: the first item in the list is always the updated edgelist (dict, dictionary of edges with discretized timestamps) and the second item is the converted timestamps in unix format (list) if store_unix is True</p> Source code in <code>tgx/utils/graph_utils.py</code> <pre><code>def discretize_edges(edgelist: dict,\n                    time_scale: Union[int,str],\n                    store_unix: Optional[bool] = False,\n                    freq_weight: Optional[bool] = False) -&gt; list:\n    \"\"\"\n    util function for discretizing edgelist, expected timestamp on edges are unixtimestamp\n    this func supports discretization of edge timestamp \n    1. by providing the number of intervals (int), it will equally divide the data into that number of intervals. Note that the last bin can have less duration than others.\n    2. by providing a time granularity (str), it will divide the data into intervals based on the given granularity, i.e. \"hourly\", \"daily\", \"weekly\", \"monthly\", \"yearly\", the starting time of the dataset is consider the start of the first interval\n    Parameters:\n        edgelist: dict, dictionary of edges\n        time_scale: int or str, time interval to discretize the graph\n        store_unix: bool, whether to return the converted timestamps in unix format\n        freq_weight: bool, whether to weight the edges based on their frequency\n    Returns:\n        output list: the first item in the list is always the updated edgelist (dict, dictionary of edges with discretized timestamps) and the second item is the converted timestamps in unix format (list) if store_unix is True\n    \"\"\"\n    unique_ts = list(edgelist.keys())        \n    total_time = unique_ts[-1] - unique_ts[0]\n\n    #! adding intermediate hour and days, to remove\n\n    if time_scale is not None:\n        if isinstance(time_scale, int):\n            interval_size = total_time // time_scale  #integer timestamp of the bin, discounting any bin that has a smaller duration than others\n        elif isinstance(time_scale, str): \n            if time_scale == \"minutely\":\n                interval_size = SEC_IN_MIN\n            elif time_scale == \"hourly\":\n                interval_size = SEC_IN_HOUR\n            elif time_scale == \"2hourly\":\n                interval_size = 2*SEC_IN_HOUR\n            elif time_scale == \"4hourly\":\n                interval_size = 4*SEC_IN_HOUR\n            elif time_scale == \"6hourly\":\n                interval_size = 6*SEC_IN_HOUR\n            elif time_scale == \"12hourly\":\n                interval_size = 12*SEC_IN_HOUR\n            elif time_scale == \"daily\":\n                interval_size = SEC_IN_DAY\n            elif time_scale == \"2daily\":\n                interval_size = 2*SEC_IN_DAY\n            elif time_scale == \"4daily\":\n                interval_size = 4*SEC_IN_DAY\n            elif time_scale == \"weekly\":\n                interval_size = SEC_IN_WEEK\n            elif time_scale == \"monthly\":\n                interval_size = SEC_IN_MONTH\n            elif time_scale == \"yearly\":\n                interval_size = SEC_IN_YEAR\n            elif time_scale == \"biyearly\":\n                interval_size = SEC_IN_BIYEARLY\n        else:\n            raise TypeError(\"Invalid time interval\")\n    else:\n        raise TypeError(\"Please provide a time interval\")\n\n    num_time_scale = ceiling_division(total_time, interval_size)    \n    print(f'Discretizing data to {num_time_scale} timestamps...')\n\n    updated_edgelist = {}\n\n    if (store_unix):\n        unix_dict = []\n        start_time = int(unique_ts[0])\n\n    for ts, edges_list in edgelist.items():\n        #? no longer assume ts start with 0\n        bin_ts = ceiling_division(ts-start_time, interval_size)  #will correctly put edges into the last bin\n\n        for edge in edges_list:\n            if bin_ts not in updated_edgelist:\n                updated_edgelist[bin_ts] = {edge: 1}\n            else:\n                if (not freq_weight):\n                    updated_edgelist[bin_ts][edge] = 1\n                else:\n                    if (edge in updated_edgelist[bin_ts]):\n                        updated_edgelist[bin_ts][edge] += 1\n                    else:\n                        updated_edgelist[bin_ts][edge] = 1\n\n        if (store_unix):\n            #! should use bin_ts here\n            unix_ts = start_time + bin_ts * interval_size\n\n            # unix_ts = start_time + int(ts // interval_size) * interval_size #round to the nearest start time\n            unix_ts = int(unix_ts)\n            unix_dict.extend([unix_ts] * len(edges_list))\n\n    output = [updated_edgelist]\n    if (store_unix):\n        output.append(unix_dict)\n    return output\n</code></pre>"},{"location":"utils/graph_utils/#tgx.utils.graph_utils.is_discretized","title":"<code>is_discretized(edgelist, max_timestamps=10000)</code>","text":"<p>Check if an edgelist is discretized or not.</p> Source code in <code>tgx/utils/graph_utils.py</code> <pre><code>def is_discretized(edgelist: Optional[dict],\n                   max_timestamps: Optional[int] = 10000) -&gt; bool:\n    r\"\"\"\n    Check if an edgelist is discretized or not.\n    \"\"\"\n    timestamps = list(edgelist.keys())\n    discretized = True\n    if len(timestamps) &gt; max_timestamps:\n        discretized = False\n\n    return discretized\n</code></pre>"},{"location":"utils/graph_utils/#tgx.utils.graph_utils.node_list","title":"<code>node_list(dict_edgelist)</code>","text":"<p>create a list of nodes from edgelist dictionary</p> Source code in <code>tgx/utils/graph_utils.py</code> <pre><code>def node_list(dict_edgelist: dict) -&gt; list:\n\n    \"\"\"\n    create a list of nodes from edgelist dictionary\n    \"\"\"\n    node_list = {}\n    for _, edge_data in dict_edgelist.items():\n        for (u,v), _ in edge_data.items():\n            if u not in node_list:\n                node_list[u] = 1\n            if v not in node_list:\n                node_list[v] = 1\n    return list(node_list.keys())\n</code></pre>"},{"location":"utils/graph_utils/#tgx.utils.graph_utils.subsampling","title":"<code>subsampling(graph, node_list=[], selection_strategy='random', N=100)</code>","text":"<p>Subsampling a part of graph by only monitoring the contacts from specific nodes' list</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>object</code> <p>graph object</p> required <code>node_list</code> <code>Optional[list]</code> <p>list, a set of nodes to extract their contacts from the graph</p> <code>[]</code> <code>selection_strategy</code> <code>str</code> <p>str, currently supports random sampling</p> <code>'random'</code> <code>N</code> <code>Optional[int]</code> <p>int, number of nodes to be randomly sampled from graph</p> <code>100</code> <p>Returns:</p> Name Type Description <code>new_edgelist</code> <code>dict</code> <p>dict, a dictionary of edges corresponding to nodes in the node_list</p> Source code in <code>tgx/utils/graph_utils.py</code> <pre><code>def subsampling(graph: object, \n                node_list: Optional[list] = [], \n                selection_strategy: str = \"random\", \n                N: Optional[int] = 100\n                ) -&gt; dict:\n    \"\"\"\n    Subsampling a part of graph by only monitoring the contacts from specific nodes' list\n\n    Parameters:\n        graph: graph object\n        node_list: list, a set of nodes to extract their contacts from the graph\n        selection_strategy: str, currently supports random sampling\n        N: int, number of nodes to be randomly sampled from graph\n\n    Returns:\n        new_edgelist: dict, a dictionary of edges corresponding to nodes in the node_list\n    \"\"\"\n    print(\"Generate graph subsample...\")\n    edgelist = graph.data\n    nodes = graph.nodes_list()\n\n    if (len(node_list) == 0): #decide on selection strategy if nodelist not provided\n        if (selection_strategy == \"random\"):\n            node_list = list(np.random.choice(nodes, size = N, replace = False))\n        else:\n            raise ValueError(\"Selection strategy not supported\", selection_strategy)\n\n    new_edgelist = {}\n    for t, edge_data in edgelist.items():\n                for (u,v), f in edge_data.items():\n                    if u in node_list or v in node_list:\n                        if t not in new_edgelist:\n                            new_edgelist[t] = {}\n                            new_edgelist[t][(u, v)] = f\n                        else:\n                            new_edgelist[t][(u, v)] = f\n    return new_edgelist\n</code></pre>"},{"location":"utils/graph_utils/#tgx.utils.graph_utils.train_test_split","title":"<code>train_test_split(data, val=False, ratio=[85, 15])</code>","text":"<p>Generate train/test split for the data</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>dictionary of data</p> required <code>val</code> <code>bool</code> <p>whether we want to have a validation split as well</p> <code>False</code> <code>ratio</code> <code>list</code> <p>list indication the ratio of the data in split. Sum of the list components should be 100.</p> <code>[85, 15]</code> <p>Returns:</p> Type Description <code>dict</code> <p>two (train/test) or three (train/val/test) data dictionaries</p> Source code in <code>tgx/utils/graph_utils.py</code> <pre><code>def train_test_split(data : dict, \n                     val : bool = False,\n                     ratio : list = [85, 15]) -&gt; dict:\n    \"\"\"\n    Generate train/test split for the data\n\n    Parameters:\n        data:dictionary of data\n        val: whether we want to have a validation split as well\n        ratio: list indication the ratio of the data in split. Sum of the list components should be 100.\n\n    Returns:\n        two (train/test) or three (train/val/test) data dictionaries\n    \"\"\"\n    sum = 0\n    for i in ratio:\n        sum += i\n    if sum != 100:\n        raise ValueError(\"invalid train/test split ratio. Sum of the ratios should be 100.\")\n\n    if val and len(ratio) != 3:\n        raise Exception(\"Provide train/val/test ratio\")\n    elif not val and len(ratio) == 3:\n        print(\"Warning! Data is being splitted to train and test only!\")\n\n    data_len = len(data)\n    train_split = int(data_len * ratio[0] / 100)\n    train_data = {k: v for k, v in data.items() if k &lt; train_split}\n    if val:\n        val_split = int(data_len * ratio[1] / 100) + train_split\n        val_data = {k: v for k, v in data.items() if train_split &lt;= k &lt; val_split}\n        test_data = {k: v for k, v in data.items() if val_split &lt;= k &lt;= data_len}\n        return train_data, val_data, test_data\n\n    else:\n        test_data = {k: v for k, v in data.items() if train_split &lt;= k &lt;= data_len}\n        return train_data, test_data\n</code></pre>"},{"location":"utils/plotting_utils/","title":"Plotting Utils","text":""},{"location":"utils/plotting_utils/#plotting-utils","title":"Plotting Utils","text":""},{"location":"utils/plotting_utils/#tgx.utils.plotting_utils.plot_density_map","title":"<code>plot_density_map(data, y_title, filename=None)</code>","text":"<p>Plot a density map using fig and ax Parameters:     data: A list of desired variable to be plotted     y_title: Title of the y axis     filename: Name of the output file name, containing the path</p> Source code in <code>tgx/utils/plotting_utils.py</code> <pre><code>def plot_density_map(data: list, \n                     y_title: str,\n                     filename: str = None,):\n    '''\n    Plot a density map using fig and ax\n    Parameters:\n        data: A list of desired variable to be plotted\n        y_title: Title of the y axis\n        filename: Name of the output file name, containing the path\n    '''\n    max_value = max(max(inner) for inner in data if inner)\n    c = np.zeros((max_value, len(data)))\n\n    for i, row in enumerate(data):\n        for value in row:\n            c[value - 1][i] += 1\n\n    # Plot\n    fig = plt.figure(facecolor='w', figsize=(9, 6))\n    ax = fig.add_subplot(111)\n\n    norm = mcolors.Normalize(vmin=0, vmax=1)\n    cax = ax.imshow(c, cmap='viridis', interpolation='nearest', norm=norm)\n    cbar = fig.colorbar(cax)\n    cbar.set_label('Frequency')\n\n    ax.set_title(\"Heatmap of Node Degrees Over Time\")\n    ax.set_xlabel('Time', fontsize=20)\n    ax.set_ylabel(y_title, fontsize=20)\n    ax.tick_params(labelsize=20)\n    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n\n    # Adjust the aspect ratio of the plot\n    ax.set_aspect('auto')\n\n    if filename is not None:\n        plt.savefig(f'{filename}')\n    else:\n        plt.show()\n</code></pre>"},{"location":"utils/plotting_utils/#tgx.utils.plotting_utils.plot_for_snapshots","title":"<code>plot_for_snapshots(data, y_title, filename=None, show_ave=True)</code>","text":"<p>Plot a variable for different timestamps Parameters:     data: A list of desired variable to be plotted     y_title: Title of the y axis     filename: Name of the output file name, containing the path     show_ave: Whether to plot a line showing the average of the variable over all timestamps</p> Source code in <code>tgx/utils/plotting_utils.py</code> <pre><code>def plot_for_snapshots(data: list,  \n                       y_title: str, \n                       filename: str = None, \n                       show_ave: bool=True, ):\n    '''\n    Plot a variable for different timestamps\n    Parameters:\n        data: A list of desired variable to be plotted\n        y_title: Title of the y axis\n        filename: Name of the output file name, containing the path\n        show_ave: Whether to plot a line showing the average of the variable over all timestamps\n    '''\n    ts = list(range(0, len(data)))\n    # plt.rcParams[\"font.family\"] = \"Times New Roman\"\n    fig = plt.figure(facecolor='w', figsize=(9,6))\n    ax = fig.add_subplot(111)\n    ax.plot(ts, data, color='black', lw=3)\n\n    ax.set_xlabel('Time', fontsize=20)\n    ax.set_ylabel(y_title, fontsize=20)\n    ax.tick_params(labelsize=20)\n    ax.set_xlim(0, len(ts)-1)\n    if show_ave:\n        ave_deg = [np.average(data) for i in range(len(ts))]\n        ax.plot(ts, ave_deg, color='#ca0020', linestyle='dashed', lw=3)\n    if filename is not None:\n        plt.savefig(f'{filename}')\n    else:\n        plt.show()\n</code></pre>"},{"location":"utils/plotting_utils/#tgx.utils.plotting_utils.plot_nodes_edges_per_ts","title":"<code>plot_nodes_edges_per_ts(edges, nodes, ts, filename=None, ylabel_1='Edges per Timestamp', ylabel_2='Nodes per Timestamp')</code>","text":"<p>Plot nodes and edges per timestamp in one figure Parameters:     edges: A list containing number of edges per timestamp     nodes: A list containing number of nodes per timestamp     ts: list of timestamps     filename: Name of the output file name, containing the path     ylabel_1: Label for the edges per timestamp line     ylabel_2: Label for the nodes per timestamp line</p> Source code in <code>tgx/utils/plotting_utils.py</code> <pre><code>def plot_nodes_edges_per_ts(edges: list,\n                            nodes: list, \n                            ts: list,\n                            filename: str = None,\n                            ylabel_1: str = 'Edges per Timestamp',\n                            ylabel_2: str = 'Nodes per Timestamp'):\n    \"\"\"\n    Plot nodes and edges per timestamp in one figure\n    Parameters:\n        edges: A list containing number of edges per timestamp\n        nodes: A list containing number of nodes per timestamp\n        ts: list of timestamps\n        filename: Name of the output file name, containing the path\n        ylabel_1: Label for the edges per timestamp line\n        ylabel_2: Label for the nodes per timestamp line\n    \"\"\"\n    fig = plt.figure(facecolor='w', figsize=(11, 6))\n    ax1 = fig.add_subplot(111)\n    ax2 = ax1.twinx()\n\n    c1, = ax1.plot(ts, edges, color='black', lw=3, label=ylabel_1)\n    c2, = ax2.plot(ts, nodes, color='gray', linestyle='dashed', lw=3, label=ylabel_2)\n    curves = [c1, c2]\n    ax1.legend(curves, [curve.get_label() for curve in curves], fontsize = 18)\n    ax1.set_xlabel('Time', fontsize=20)\n    ax1.set_ylabel(ylabel_1, fontsize=20)\n    ax2.set_ylabel(ylabel_2, fontsize=20)\n    ax1.tick_params(labelsize=20)\n    ax2.tick_params(labelsize=20)\n    ax1.set_ylim(0)\n    ax2.set_ylim(0)\n    ax1.set_xlim(0, len(ts)-1)\n    if filename is not None:\n        plt.savefig(f'{filename}')\n    else:\n        plt.show()\n</code></pre>"},{"location":"viz/vis_tea/","title":"TEA Plot","text":""},{"location":"viz/vis_tea/#tea-plots","title":"TEA Plots","text":""},{"location":"viz/vis_tea/#tgx.viz.TEA.TEA","title":"<code>TEA(temp_edgelist, filepath='.', fig_size=(7, 5), font_size=20, network_name=None, time_scale=None, real_dates=None, test_split=False, density=False)</code>","text":"<p>generating TEA plot</p> <p>Parameters:</p> Name Type Description Default <code>temp_edgelist</code> <code>Union[object, dict]</code> <p>a dictionary of temporal edges or a dataset object.</p> required <code>filepath</code> <code>Optional[str]</code> <p>Path to save the TEA Plot.</p> <code>'.'</code> <code>fig_size</code> <code>tuple</code> <p>Size of the figure to save.</p> <code>(7, 5)</code> <code>font_size</code> <code>int</code> <p>Size of the text in the figure.</p> <code>20</code> <code>network_name</code> <code>str</code> <p>Name of the dataset to be used in the TEA plot file.</p> <code>None</code> <code>time_scale</code> <code>Union[str, int]</code> <p>time_scale for discretizing data if already not done.</p> <code>None</code> <code>real_dates</code> <code>bool</code> <p>Whether to use the real dates from dataset.</p> <code>None</code> <code>test_split</code> <code>bool</code> <p>Whether show the test split on the plot.</p> <code>False</code> <code>density</code> <code>bool</code> <p>Whether to return edge density and edge frequency dictioneries.</p> <code>False</code> Source code in <code>tgx/viz/TEA.py</code> <pre><code>def TEA(\n        temp_edgelist : Union[object, dict], \n        filepath : Optional[str] = \".\",\n        fig_size : tuple = (7,5),\n        font_size : int = 20, \n        network_name : str = None,\n        time_scale : Union[str, int] = None, \n        real_dates : bool = None,\n        test_split : bool = False,\n        density : bool = False\n        ):\n    r\"\"\"\n    generating TEA plot\n\n    Parameters:\n        temp_edgelist: a dictionary of temporal edges or a dataset object.\n        filepath: Path to save the TEA Plot.\n        fig_size: Size of the figure to save.\n        font_size: Size of the text in the figure.\n        network_name: Name of the dataset to be used in the TEA plot file.\n        time_scale: time_scale for discretizing data if already not done.\n        real_dates: Whether to use the real dates from dataset.\n        test_split: Whether show the test split on the plot.\n        density: Whether to return edge density and edge frequency dictioneries.\n    \"\"\"\n    if isinstance(temp_edgelist, object):\n        if temp_edgelist.freq_data is None:\n            temp_edgelist.count_freq()\n        temp_edgelist = temp_edgelist.freq_data\n\n    # check number of unique timestamps:\n    unique_ts = list(temp_edgelist.keys())\n    # if len(unique_ts) &gt; max_time_scale:\n    #     inp = input(f\"There are {unique_ts} timestamps in the data.\\nDo you want to discretize the data to 1000 timestamps?(y/n)\").lower()\n    #     if inp == \"y\":\n    #         temp_edgelist = edgelist_discritizer(temp_edgelist,\n    #                                             unique_ts,\n    #                                             time_scale = max_time_scale)\n    if time_scale is not None:\n        temp_edgelist = discretize_edges(temp_edgelist,\n                                        time_scale = time_scale)\n\n\n    ts_edges_dist, ts_edges_dist_density, edge_frequency_dict = TEA_process_edgelist_per_timestamp(temp_edgelist)\n\n    TEA_plot_edges_bar(ts_edges_dist, \n                       filepath = filepath, \n                       fig_size = fig_size, \n                       font_size = font_size, \n                       network_name=network_name,\n                       real_dates = real_dates,\n                       test_split = test_split)\n\n    if density:\n        return ts_edges_dist_density, edge_frequency_dict\n</code></pre>"},{"location":"viz/vis_tea/#tgx.viz.TEA.TEA_plot_edges_bar","title":"<code>TEA_plot_edges_bar(ts_edges_dist, filepath='.', fig_size=(9, 5), font_size=20, network_name=None, real_dates=None, time_scale=None, test_split=False, show=False)</code>","text":"<p>Making TEA plot and save into pdf file. Args:     ts_edges_dist: list of dictionaries containing the edge distribution over time.     filepath: Path to save the TEA Plot.     fig_size: Size of the figure to save.     font_size: Size of the text in the figure.     network_name: Name of the dataset to be used in the TEA plot file.     real_dates: list of real dates as ticks     time_scale: time_scale for discretizing data if already not done.     test_split: Whether show the test split on the plot.     show: Whether to show the plot.</p> Source code in <code>tgx/viz/TEA.py</code> <pre><code>def TEA_plot_edges_bar(ts_edges_dist: list, \n                   filepath: str = \".\", \n                   fig_size: list = (9,5),\n                   font_size: int = 20,\n                   network_name: str = None,\n                   real_dates: list = None,\n                   time_scale: list = None,\n                   test_split: bool = False,\n                   show: bool =False):\n    r\"\"\"\n    Making TEA plot and save into pdf file.\n    Args:\n        ts_edges_dist: list of dictionaries containing the edge distribution over time.\n        filepath: Path to save the TEA Plot.\n        fig_size: Size of the figure to save.\n        font_size: Size of the text in the figure.\n        network_name: Name of the dataset to be used in the TEA plot file.\n        real_dates: list of real dates as ticks\n        time_scale: time_scale for discretizing data if already not done.\n        test_split: Whether show the test split on the plot.\n        show: Whether to show the plot.\n    \"\"\"\n\n\n    ts_edges_dist_df = pd.DataFrame(ts_edges_dist, columns=['ts', 'new', 'repeated',\n                                                            'not_repeated',\n                                                            'total_curr_ts',\n                                                            'total_seen_until_curr_ts'])\n\n\n    ### Additional Stats ###\n    mean = ts_edges_dist_df.mean(axis=0)\n    # print(\"INFO: Network Name:\", network_name)\n    # print(\"INFO: AVG. stats. over all timestamps: \", mean)\n    # print(\"INFO: ratio of avg.(new)/avg.(total_curr_ts): {:.2f}\".format(mean['new'] / mean['total_curr_ts']))\n    ###\n\n    fig, ax = plt.subplots(figsize=fig_size)  # lastfm, mooc, reddit, UNtrade, UNvote\n    plt.subplots_adjust(bottom=0.2, left=0.2)\n    font_size = font_size\n    ticks_font_size = 15\n    plt.yticks(fontsize=ticks_font_size)\n    plt.xticks(fontsize=ticks_font_size)\n    if real_dates is not None:\n        start = real_dates[0]\n        end = real_dates[1]\n        metric = real_dates[2]\n        create_ts_list(start, end, metric=metric, interval=time_scale)\n    else:\n        duration = ts_edges_dist_df['ts'].tolist()\n        timestamps = [i for i in range(len(duration))]\n\n    new = ts_edges_dist_df['new'].tolist()\n    repeated = ts_edges_dist_df['repeated'].tolist()\n    # print(len(timestamps), repeated, new)\n    # plotting stuffs\n    # bar plot\n    plt.bar(timestamps, repeated, label='Repeated', color='#404040', alpha=0.4)\n    plt.bar(timestamps, new, label='New', bottom=repeated, color='#ca0020', alpha=0.8, hatch='//')\n    # test split line\n    if test_split:\n        plt.axvline(x=(timestamps[int(0.85 * len(timestamps))]), color=\"blue\", linestyle=\"--\", linewidth=2)\n        plt.text((timestamps[int(0.85 * len(timestamps))]), 0,\n                'x', va='center', ha='center', fontsize=font_size, fontweight='heavy', color='blue')\n\n    plt.margins(x=0)\n    plt.xlabel(\"Timestamp\", fontsize=font_size)\n    plt.ylabel(\"Number of edges\", fontsize=font_size)\n    plt.legend(fontsize = 13)\n    if filepath is not None:\n        plt.savefig(f\"{filepath}/{network_name}_TEA.pdf\")\n        print(\"plot saved as \" + f\"{filepath}/{network_name}_TEA.pdf\")\n    if (show):\n        plt.show()\n</code></pre>"},{"location":"viz/vis_tet/","title":"TET Plot","text":""},{"location":"viz/vis_tet/#tet-plots","title":"TET Plots","text":""},{"location":"viz/vis_tet/#tgx.viz.TET.TET","title":"<code>TET(temp_edgelist, filepath='.', time_scale=None, network_name=None, add_frame=True, test_split=False, figsize=(9, 5), axis_title_font_size=20, ticks_font_size=20, show=True)</code>","text":"<p>Generate TET plots Args:     temp_edgelist: a dictionary of temporal edges or a dataset object.     filepath: Path to save the TEA Plot.     figsize: Size of the figure to save.     axis_title_font_size: The font size of xis titles.     ticks_font_size: Size of the text in the figure.     add_frame: Add the frame to the plot.     network_name: Name of the dataset to be used in the TEA plot file.     time_scale: time_scale for discretizing data if already not done.     test_split: Whether show the test split on the plot.     max_time_scale: Maximum number of time_scale to discretize data.     show: Whether to show the plot.</p> Source code in <code>tgx/viz/TET.py</code> <pre><code>def TET(temp_edgelist : Union[object, dict],\n        filepath: Optional[str] = \".\", \n        time_scale : Union[str, int] = None,\n        network_name : str = None,\n        add_frame : bool = True,\n        test_split : bool = False,\n        figsize : tuple = (9, 5),\n        axis_title_font_size : int = 20,\n        ticks_font_size : int = 20,\n        show: bool = True):\n    r\"\"\"\n    Generate TET plots\n    Args:\n        temp_edgelist: a dictionary of temporal edges or a dataset object.\n        filepath: Path to save the TEA Plot.\n        figsize: Size of the figure to save.\n        axis_title_font_size: The font size of xis titles.\n        ticks_font_size: Size of the text in the figure.\n        add_frame: Add the frame to the plot.\n        network_name: Name of the dataset to be used in the TEA plot file.\n        time_scale: time_scale for discretizing data if already not done.\n        test_split: Whether show the test split on the plot.\n        max_time_scale: Maximum number of time_scale to discretize data.\n        show: Whether to show the plot.\n    \"\"\"\n    if isinstance(temp_edgelist, object):\n        if temp_edgelist.freq_data is None:\n            temp_edgelist.count_freq()\n        temp_edgelist = temp_edgelist.freq_data\n\n    # check number of unique timestamps:\n    unique_ts = list(temp_edgelist.keys())\n    # if len(unique_ts) &gt; max_time_scale:\n    #     inp = input(f\"There are {unique_ts} timestamps in the data.\\nDo you want to discretize the data to 1000 timestamps?(y/n)\").lower()\n    #     if inp == \"y\":\n    #         temp_edgelist = edgelist_discritizer(temp_edgelist,\n    #                                             unique_ts,\n    #                                             time_scale = max_time_scale)\n    if time_scale is not None:\n        temp_edgelist = discretize_edges(temp_edgelist,\n                                        time_scale = time_scale)\n\n    edge_last_ts = generate_edge_last_timestamp(temp_edgelist)\n    edge_idx_map = generate_edge_idx_map(temp_edgelist, edge_last_ts)\n    idx_edge_map = {v: k for k, v in edge_idx_map.items()}  # key: edge index; value: actual edge (source, destination)\n    print(\"Info: Number of distinct edges (from index-edge map): {}\".format(len(idx_edge_map)))\n\n    unique_ts_list = list(temp_edgelist.keys())\n    e_presence_mat = generate_edge_presence_matrix(unique_ts_list, idx_edge_map, edge_idx_map, temp_edgelist)\n    print(\"Info: edge-presence-matrix shape: {}\".format(e_presence_mat.shape))\n    # print(np.unique(e_presence_mat, return_counts=True))\n    e_presence_mat, test_split_ts_value = process_presence_matrix(e_presence_mat, test_ratio_p=0.85)\n    print(\"Info: edge-presence-matrix shape: {}\".format(e_presence_mat.shape))\n    # print(np.unique(e_presence_mat, return_counts=True))\n    fig_param = set_fig_param(network_name, \n                              fig_name = filepath,\n                              figsize = figsize,\n                              axis_title_font_size = axis_title_font_size,\n                              ticks_font_size = ticks_font_size)\n\n    plot_edge_presence_matrix(e_presence_mat, test_split_ts_value, unique_ts_list, list(idx_edge_map.keys()),\n                              fig_param, test_split = test_split, add_frames=add_frame, show=show)\n    return \n</code></pre>"},{"location":"viz/vis_tet/#tgx.viz.TET.generate_edge_idx_map","title":"<code>generate_edge_idx_map(edges_per_ts, edge_last_ts)</code>","text":"<p>generates index for edges according to two-level sorting policy: 1. the first level is based on their first appearance timestamp 2. the second level is based on their last appearance timestamp</p> Source code in <code>tgx/viz/TET.py</code> <pre><code>def generate_edge_idx_map(edges_per_ts, edge_last_ts):\n    \"\"\"\n    generates index for edges according to two-level sorting policy:\n    1. the first level is based on their first appearance timestamp\n    2. the second level is based on their last appearance timestamp\n    \"\"\"\n    edge_idx_map = {}  # key: actual edge (source, destination), value: edge index\n    distinct_edge_idx = 0\n    for ts, ts_e_list in edges_per_ts.items():\n        e_last_ts_this_timestamp = {}\n        for e in ts_e_list:\n            e_last_ts_this_timestamp[e] = edge_last_ts[e]\n        e_last_ts_this_timestamp = dict(sorted(e_last_ts_this_timestamp.items(), key=lambda item: item[1]))\n        for e in e_last_ts_this_timestamp:\n            if e not in edge_idx_map:\n                edge_idx_map[e] = distinct_edge_idx\n                distinct_edge_idx += 1\n\n    return edge_idx_map\n</code></pre>"},{"location":"viz/vis_tet/#tgx.viz.TET.generate_edge_last_timestamp","title":"<code>generate_edge_last_timestamp(edges_per_ts)</code>","text":"<p>generates a dictionary containing the last timestamp of each edge</p> Source code in <code>tgx/viz/TET.py</code> <pre><code>def generate_edge_last_timestamp(edges_per_ts):\n    \"\"\"generates a dictionary containing the last timestamp of each edge\"\"\"\n    edge_last_ts = {}\n    for ts, e_list in edges_per_ts.items():\n        for e in e_list:\n            if e not in edge_last_ts:\n                edge_last_ts[e] = ts\n            else:\n                edge_last_ts[e] = max(ts, edge_last_ts[e])\n    return edge_last_ts\n</code></pre>"},{"location":"viz/vis_tet/#tgx.viz.TET.generate_edge_presence_matrix","title":"<code>generate_edge_presence_matrix(unique_ts_list, idx_edge_map, edge_idx_map, edges_per_ts)</code>","text":"<p>Returns presence matrix with values 0 and 1 which indicate: value = 0 : edge is not present in this timestamp value = 1 : edge is present in this timestamp</p> <p>shape: (ts, total number of edges)</p> Source code in <code>tgx/viz/TET.py</code> <pre><code>def generate_edge_presence_matrix(unique_ts_list, idx_edge_map, edge_idx_map, edges_per_ts):\n    '''\n    Returns presence matrix with values 0 and 1 which indicate:\n    value = 0 : edge is not present in this timestamp\n    value = 1 : edge is present in this timestamp\n\n    shape: (ts, total number of edges)\n    '''\n    num_unique_ts = len(unique_ts_list)\n    num_unique_edge = len(idx_edge_map)\n    e_presence_mat = np.zeros([num_unique_ts, num_unique_edge], dtype=np.int8)\n    unique_ts_list = np.sort(unique_ts_list)\n\n    for x, ts in tqdm(enumerate(unique_ts_list)):\n        es_ts = edges_per_ts[ts]\n        for e in es_ts:\n            e_presence_mat[num_unique_ts - x - 1, edge_idx_map[e]] = E_PRESENCE_GENERAL\n\n    return e_presence_mat\n</code></pre>"},{"location":"viz/vis_tet/#tgx.viz.TET.process_presence_matrix","title":"<code>process_presence_matrix(e_presence_matrix, test_ratio_p)</code>","text":"<p>there are 4 types of edge presence: 1. only in train 2. in train and in test 3. in test and train (which is the number 2 but in later timestamps) 4. only in test X: timestamp Y: edge index</p> Source code in <code>tgx/viz/TET.py</code> <pre><code>def process_presence_matrix(e_presence_matrix, test_ratio_p):\n    \"\"\"\n    there are 4 types of edge presence:\n    1. only in train\n    2. in train and in test\n    3. in test and train (which is the number 2 but in later timestamps)\n    4. only in test\n    X: timestamp\n    Y: edge index\n    \"\"\"\n    num_unique_ts = e_presence_matrix.shape[0]\n    num_unique_edges = e_presence_matrix.shape[1]\n    ts_idx_list = [i for i in range(num_unique_ts)]\n\n    # generating timestamp list for train and test:\n    test_split_ts_value = int(np.quantile(ts_idx_list, test_ratio_p))\n    train_ts_list = [ts for ts in ts_idx_list if ts &lt;= test_split_ts_value]  # any timestamp in train/validation split\n    test_ts_list = [ts for ts in ts_idx_list if ts &gt; test_split_ts_value]  # test_split_ts_value is in train\n\n    # first level processing: differentiate train set edges: 1) Only in train set, 2) in train &amp; test set\n    print(\"First level processing: \")\n    print(\"Detecting edges present in train &amp; test sets\")\n    for tr_ts in tqdm(train_ts_list):\n        for eidx in range(num_unique_edges):\n            if e_presence_matrix[num_unique_ts - tr_ts - 1, eidx] == E_PRESENCE_GENERAL:\n                for test_ts_idx in range(test_split_ts_value + 1, num_unique_ts):\n                    if e_presence_matrix[num_unique_ts - test_ts_idx - 1, eidx] == E_PRESENCE_GENERAL:  # if seen in\n                        # the test set\n                        e_presence_matrix[num_unique_ts - tr_ts - 1, eidx] = E_TRAIN_AND_TEST\n                        break\n\n    # differentiate test set edges: 1) transductive (seen in train, repeating in test), 2) inductive (only in test)\n    print(\"Detecting transductive edges (seen in train, repeating in test)\")\n    for ts in tqdm(test_ts_list):\n        for eidx in range(num_unique_edges):\n            if e_presence_matrix[num_unique_ts - ts - 1, eidx] == E_PRESENCE_GENERAL:\n                for prev_ts_idx in range(test_split_ts_value, -1, -1):\n                    if e_presence_matrix[num_unique_ts - prev_ts_idx - 1, eidx] == E_TRAIN_AND_TEST:  # if seen in\n                        # the training set\n                        e_presence_matrix[num_unique_ts - ts - 1, eidx] = E_TRANSDUCTIVE\n                        break\n\n    # second level processing\n    print(\"Second level processing:\")\n    print(\"Detecting edges 1) Only in train set, 2) only in test (inductive)\")\n    for ts in tqdm(range(num_unique_ts)):\n        for eidx in range(num_unique_edges):\n            if ts &lt;= test_split_ts_value:\n                if e_presence_matrix[num_unique_ts - ts - 1, eidx] == E_PRESENCE_GENERAL:\n                    e_presence_matrix[num_unique_ts - ts - 1, eidx] = E_ONLY_TRAIN\n            else:\n                if e_presence_matrix[num_unique_ts - ts - 1, eidx] == E_PRESENCE_GENERAL:\n                    e_presence_matrix[num_unique_ts - ts - 1, eidx] = E_INDUCTIVE\n\n    return e_presence_matrix, test_split_ts_value\n</code></pre>"}]}